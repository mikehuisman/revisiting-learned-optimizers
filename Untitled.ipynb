{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)]\n",
      "tensor([ 0.0029, -0.0021, -0.0044, -0.0181,  0.0144, -0.0546, -0.0056,  0.0205,\n",
      "         0.0225,  0.0021,  0.0519, -0.0327, -0.0236,  0.0265, -0.0615, -0.1014,\n",
      "        -0.0164, -0.0205,  0.0128, -0.0094,  0.0582,  0.0145, -0.0221,  0.0345,\n",
      "        -0.0137,  0.0113, -0.0179,  0.0642, -0.0025,  0.0502, -0.0028, -0.0185,\n",
      "         0.0694,  0.0093, -0.0236,  0.0228, -0.0123,  0.0157,  0.0285,  0.0226,\n",
      "         0.0190, -0.0088, -0.0623, -0.0065, -0.0062,  0.0015,  0.0193, -0.0351,\n",
      "         0.0031, -0.0201,  0.0014, -0.0163,  0.0468,  0.0038, -0.0161, -0.0209,\n",
      "         0.0066, -0.0112,  0.0115,  0.0110, -0.0252, -0.0021,  0.0235, -0.0078])\n",
      "tensor([-0.0152, -0.0173,  0.0279,  0.0026,  0.0303, -0.0314,  0.0721, -0.0372,\n",
      "         0.0062, -0.0433,  0.0462, -0.0106, -0.0335,  0.1000, -0.0165, -0.0949,\n",
      "        -0.0109, -0.0363,  0.0472, -0.0151,  0.0731, -0.0446,  0.0341,  0.0717,\n",
      "        -0.0346,  0.0434, -0.0216,  0.0578, -0.0535,  0.0734, -0.0388,  0.0452,\n",
      "         0.0461, -0.0583, -0.0285,  0.0297,  0.0379,  0.0362,  0.0896,  0.0622,\n",
      "         0.1367, -0.0647, -0.0433,  0.0621, -0.0231,  0.1008, -0.0174,  0.0561,\n",
      "         0.0268, -0.0597, -0.0673, -0.0479,  0.1505, -0.0627,  0.0578, -0.0409,\n",
      "         0.0025, -0.0717,  0.0478,  0.0919,  0.0117,  0.0335,  0.0225, -0.0022])\n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)]\n",
      "tensor([-2.4988e-02, -1.1079e-02,  1.0300e-02,  6.7361e-03, -1.1575e-02,\n",
      "        -1.1072e-02,  3.4068e-02,  4.4012e-03, -1.4894e-02, -1.2437e-02,\n",
      "         1.0702e-02, -2.4866e-02, -1.5146e-03,  1.7378e-02,  2.3794e-02,\n",
      "        -2.7565e-02, -1.0927e-02, -1.4137e-03, -9.6209e-03, -3.1373e-02,\n",
      "         1.7490e-03,  2.2190e-02,  2.0785e-02, -2.2975e-02,  9.8382e-03,\n",
      "         2.3244e-03,  7.4013e-03, -8.3725e-03, -9.2371e-03, -1.1284e-02,\n",
      "         6.5342e-03, -2.4277e-03, -3.5384e-02, -9.0509e-05,  2.0454e-02,\n",
      "        -1.2560e-02, -1.3853e-03,  1.3227e-02, -6.6153e-03,  3.8969e-03,\n",
      "        -6.3104e-03, -2.8113e-02, -1.2428e-02,  5.4868e-03, -4.3571e-03,\n",
      "        -2.1577e-02,  4.8318e-02,  1.6212e-02,  6.0371e-03,  1.9925e-02,\n",
      "         1.0299e-02, -3.1377e-02, -1.6737e-02,  5.2315e-03,  2.7097e-02,\n",
      "        -1.2884e-02, -6.4399e-03, -1.9861e-02, -2.9531e-03,  2.0913e-02,\n",
      "        -1.9744e-02,  3.8707e-02,  2.4950e-02,  4.7485e-02])\n",
      "tensor([ 0.0044, -0.0078,  0.0017,  0.0071, -0.0147, -0.0076,  0.0165,  0.0031,\n",
      "         0.0013, -0.0110,  0.0003, -0.0050, -0.0071, -0.0056,  0.0039,  0.0056,\n",
      "         0.0005,  0.0062,  0.0138,  0.0064,  0.0009,  0.0106, -0.0008, -0.0005,\n",
      "         0.0082, -0.0099, -0.0066,  0.0011, -0.0014, -0.0093,  0.0089,  0.0109,\n",
      "         0.0016,  0.0080, -0.0037,  0.0061, -0.0154,  0.0106,  0.0002, -0.0087,\n",
      "         0.0123,  0.0013,  0.0089, -0.0066, -0.0019, -0.0012,  0.0091,  0.0043,\n",
      "         0.0066,  0.0007,  0.0044, -0.0078, -0.0064, -0.0030, -0.0006, -0.0072,\n",
      "        -0.0064, -0.0100,  0.0112, -0.0098, -0.0152,  0.0039,  0.0001,  0.0002])\n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)]\n",
      "tensor([-0.0165, -0.0014,  0.0057,  0.0114, -0.0083,  0.0058, -0.0041, -0.0084,\n",
      "         0.0025, -0.0036, -0.0127, -0.0152, -0.0038,  0.0043, -0.0028,  0.0150,\n",
      "        -0.0131,  0.0113,  0.0009, -0.0157, -0.0133, -0.0169, -0.0002, -0.0107,\n",
      "        -0.0097, -0.0019, -0.0086,  0.0048,  0.0184,  0.0006,  0.0010, -0.0220,\n",
      "        -0.0203,  0.0136,  0.0059,  0.0161, -0.0093,  0.0029,  0.0205,  0.0154,\n",
      "        -0.0155, -0.0110, -0.0035,  0.0064,  0.0047, -0.0015,  0.0056, -0.0109,\n",
      "         0.0004,  0.0169,  0.0152, -0.0135,  0.0010, -0.0126,  0.0055,  0.0265,\n",
      "         0.0099,  0.0084,  0.0311,  0.0006, -0.0023,  0.0042,  0.0030, -0.0058])\n",
      "tensor([-7.4438e-03, -2.8617e-03,  1.0209e-03, -8.0766e-05,  9.8232e-03,\n",
      "         3.6530e-03,  2.1753e-03, -5.7671e-03,  1.9208e-03,  1.6102e-03,\n",
      "         5.1196e-03, -2.3092e-03, -1.8797e-03, -3.8159e-03,  3.1224e-03,\n",
      "        -5.8948e-03,  7.7147e-03,  6.5024e-03, -3.7604e-03, -2.0629e-03,\n",
      "         5.7574e-03,  4.5127e-03,  2.9780e-03,  7.1814e-03, -8.1560e-03,\n",
      "         2.5457e-03, -7.2700e-03,  1.1621e-02,  8.6712e-03, -4.0794e-03,\n",
      "        -3.6690e-03, -3.8479e-03,  4.4342e-03,  3.9821e-03,  8.8901e-04,\n",
      "         2.4022e-03,  6.6533e-03,  1.1377e-02,  4.7207e-03,  8.5785e-03,\n",
      "        -5.6821e-03,  1.7067e-03, -5.1373e-03,  3.9606e-03, -8.0832e-04,\n",
      "        -5.3424e-04,  8.9611e-04, -1.0768e-03,  1.0199e-03, -3.5586e-03,\n",
      "         4.4268e-04, -3.9083e-03,  5.7514e-03, -5.4953e-03, -3.1012e-03,\n",
      "         2.4573e-04,  5.7784e-03, -7.8040e-03,  1.1959e-02,  4.3650e-03,\n",
      "         3.5596e-03,  4.7476e-03, -5.9128e-03,  1.1315e-02])\n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)]\n",
      "tensor([ 0.0045,  0.0025, -0.0402, -0.0144,  0.0030, -0.0148,  0.0316, -0.0061,\n",
      "         0.0175,  0.0315,  0.0067,  0.0025, -0.0153,  0.0508, -0.0326,  0.0046,\n",
      "         0.0206,  0.0338,  0.0112, -0.0110,  0.0428, -0.0341, -0.0067,  0.0028,\n",
      "         0.0322, -0.0275,  0.0058, -0.0169,  0.0026, -0.0266,  0.0117,  0.0194,\n",
      "        -0.0058,  0.0202, -0.0024, -0.0161, -0.0112,  0.0339, -0.0110, -0.0115,\n",
      "         0.0140,  0.0028, -0.0210, -0.0233,  0.0037, -0.0046,  0.0051, -0.0194,\n",
      "         0.0112,  0.0136,  0.0188,  0.0032,  0.0202, -0.0027, -0.0003,  0.0059,\n",
      "         0.0174, -0.0120, -0.0323,  0.0125, -0.0062,  0.0279, -0.0012,  0.0080])\n",
      "tensor([ 2.1995e-02, -9.7274e-03, -1.5179e-02, -7.8886e-03,  9.6950e-03,\n",
      "        -1.0557e-02,  1.9021e-02, -2.2104e-03,  9.3608e-03,  2.0426e-02,\n",
      "         1.2219e-02,  1.1386e-02, -1.3690e-02,  1.8687e-02, -2.7032e-02,\n",
      "         1.4927e-02,  2.3673e-02,  2.1905e-02, -4.6269e-03, -4.8512e-03,\n",
      "         2.3944e-02, -2.2634e-02, -2.8817e-03,  6.9530e-03,  2.8764e-02,\n",
      "        -7.4262e-03,  7.2580e-03, -5.4653e-03, -3.4236e-03, -1.7850e-02,\n",
      "         8.1419e-03,  1.4098e-02, -1.3085e-02,  6.3549e-03, -1.1390e-04,\n",
      "        -1.4166e-02, -6.1084e-03,  2.0882e-02, -2.4001e-02, -1.8116e-02,\n",
      "         3.4424e-03,  3.8118e-03, -2.6460e-02, -2.8548e-02,  2.3943e-03,\n",
      "         4.4167e-03, -8.1427e-03, -8.2907e-03,  7.3140e-03,  5.6251e-03,\n",
      "         1.5801e-02,  8.3202e-03,  1.1576e-02,  1.9525e-02,  7.2891e-03,\n",
      "        -2.8332e-03,  4.3125e-03,  7.9599e-03, -1.7117e-02,  7.9888e-04,\n",
      "        -3.9274e-05,  9.3246e-03,  1.5726e-03, -1.0253e-02])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from networks import Conv4, ConvBlock\n",
    "from image_loader import numpy_img_to_torch\n",
    "\n",
    "np.random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "rnd1 = numpy_img_to_torch(np.random.rand(20, 84, 84, 3))\n",
    "net = Conv4(dev=\"cpu\", train_classes=5, eval_classes=5) #ConvBlock()\n",
    "\n",
    "net(rnd1)\n",
    "rnd2 = numpy_img_to_torch(np.random.rand(20, 84, 84, 3))\n",
    "pred = net(rnd2)\n",
    "lfn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = lfn(pred, torch.randint(low=0,high=5,size=[20]))\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "for m in net.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        print([_ for _ in m.parameters()])\n",
    "        for p in m.parameters():\n",
    "            print(p.grad)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.1623, -0.0017,  0.0474],\n",
      "          [-0.0299, -0.1153, -0.1814],\n",
      "          [ 0.0328,  0.0757, -0.1247]],\n",
      "\n",
      "         [[-0.0926,  0.0803,  0.0312],\n",
      "          [-0.1704,  0.1027,  0.1454],\n",
      "          [-0.0988,  0.0387,  0.0800]],\n",
      "\n",
      "         [[ 0.0039, -0.0360,  0.1487],\n",
      "          [-0.0547,  0.1525,  0.1786],\n",
      "          [-0.1867,  0.0908,  0.1110]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1720, -0.0133,  0.1300],\n",
      "          [-0.1436, -0.1104, -0.0792],\n",
      "          [-0.0509, -0.0066,  0.0674]],\n",
      "\n",
      "         [[ 0.0087,  0.0206,  0.0270],\n",
      "          [-0.0970,  0.0400,  0.0800],\n",
      "          [-0.1621,  0.1012,  0.1042]],\n",
      "\n",
      "         [[-0.1638,  0.0293,  0.0713],\n",
      "          [ 0.1578,  0.1033,  0.0822],\n",
      "          [-0.1699,  0.1017,  0.1795]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1901,  0.1152, -0.1482],\n",
      "          [ 0.0663, -0.1590,  0.0401],\n",
      "          [-0.0292, -0.1539, -0.1601]],\n",
      "\n",
      "         [[ 0.0139,  0.1563, -0.0862],\n",
      "          [-0.1825, -0.1088,  0.0695],\n",
      "          [-0.0366, -0.1760, -0.0197]],\n",
      "\n",
      "         [[-0.0721,  0.1476, -0.0823],\n",
      "          [-0.0906,  0.0757, -0.1253],\n",
      "          [-0.0314, -0.0129,  0.1761]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0092, -0.0724,  0.0079],\n",
      "          [-0.1846,  0.0609, -0.0990],\n",
      "          [-0.1812, -0.0003,  0.1095]],\n",
      "\n",
      "         [[ 0.0556,  0.1034,  0.0860],\n",
      "          [-0.0683,  0.1477,  0.0785],\n",
      "          [ 0.0538, -0.0146,  0.0169]],\n",
      "\n",
      "         [[ 0.1140,  0.1537,  0.1509],\n",
      "          [ 0.0543, -0.1496,  0.0589],\n",
      "          [ 0.1173,  0.0619, -0.1451]]],\n",
      "\n",
      "\n",
      "        [[[-0.1052, -0.0620, -0.0413],\n",
      "          [-0.0037,  0.1811, -0.0876],\n",
      "          [-0.0294, -0.1718, -0.0296]],\n",
      "\n",
      "         [[ 0.0218,  0.1147,  0.0902],\n",
      "          [-0.0124, -0.1755, -0.1344],\n",
      "          [-0.0112, -0.1311,  0.0306]],\n",
      "\n",
      "         [[-0.1071,  0.0281, -0.0552],\n",
      "          [ 0.1287, -0.1738,  0.1219],\n",
      "          [-0.0433, -0.1061,  0.0264]]],\n",
      "\n",
      "\n",
      "        [[[-0.1003,  0.1618,  0.0124],\n",
      "          [-0.0923, -0.0875, -0.1918],\n",
      "          [ 0.1647,  0.1815, -0.0043]],\n",
      "\n",
      "         [[ 0.0018,  0.1885, -0.0765],\n",
      "          [-0.0617,  0.0443, -0.1316],\n",
      "          [-0.1389,  0.0111,  0.1312]],\n",
      "\n",
      "         [[ 0.0216,  0.0490, -0.1049],\n",
      "          [-0.1563,  0.1193,  0.1874],\n",
      "          [-0.0201, -0.0811, -0.1108]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1394,  0.0061, -0.1372, -0.1611, -0.1246,  0.0576,  0.1232, -0.1770,\n",
      "         0.0010,  0.0921,  0.0504,  0.0260, -0.1894, -0.1154,  0.1402, -0.1499,\n",
      "        -0.0906,  0.0410,  0.0408, -0.1846,  0.0479, -0.0007, -0.1798, -0.0698,\n",
      "        -0.1299,  0.0537, -0.0612,  0.0558, -0.0935,  0.1530,  0.1436,  0.1439,\n",
      "         0.0437, -0.1780, -0.1611,  0.0609, -0.0946, -0.1132,  0.0526,  0.1230,\n",
      "         0.1698, -0.1279, -0.0513,  0.0751, -0.0552, -0.1782,  0.0083,  0.0035,\n",
      "         0.0197, -0.0966,  0.0559,  0.1427, -0.1002, -0.1715, -0.1534,  0.0060,\n",
      "         0.1832, -0.1724,  0.1263, -0.1617,  0.1727, -0.0617, -0.1205, -0.0349],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-3.7927e-02,  1.8433e-02,  1.1347e-02],\n",
      "          [ 3.7656e-02,  8.7175e-03,  3.1939e-02],\n",
      "          [-2.1264e-02,  2.5047e-02,  1.4723e-03]],\n",
      "\n",
      "         [[ 1.6700e-02, -3.6713e-03, -3.6093e-02],\n",
      "          [ 2.6540e-02, -3.2410e-02, -2.7422e-03],\n",
      "          [-4.8145e-03, -1.1295e-03,  3.8680e-02]],\n",
      "\n",
      "         [[-1.3997e-02,  3.4379e-02, -1.9653e-02],\n",
      "          [ 3.5368e-02,  2.9425e-02,  5.5878e-04],\n",
      "          [-1.1563e-02,  2.9978e-02, -1.6815e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1353e-02, -7.7124e-03,  3.6018e-02],\n",
      "          [-2.7176e-02, -5.1315e-03,  2.8327e-02],\n",
      "          [-2.4774e-02,  7.4069e-03, -1.3264e-02]],\n",
      "\n",
      "         [[-2.7867e-02,  2.2814e-02, -3.2717e-02],\n",
      "          [-1.0275e-02,  1.9114e-02, -3.2051e-02],\n",
      "          [-6.8959e-03,  3.3153e-02,  2.8298e-03]],\n",
      "\n",
      "         [[-5.3128e-03,  1.4971e-02, -2.6541e-02],\n",
      "          [-3.8398e-03, -1.4895e-02, -1.1782e-02],\n",
      "          [ 4.1084e-02, -1.4202e-02,  2.3835e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7566e-02, -2.2950e-02, -1.2309e-02],\n",
      "          [-1.8173e-04, -1.7255e-02, -5.2971e-03],\n",
      "          [-3.7603e-02,  2.3253e-02, -8.5642e-03]],\n",
      "\n",
      "         [[-2.4765e-02,  2.5187e-02, -3.2083e-02],\n",
      "          [ 9.9596e-04, -2.9622e-02,  6.6066e-04],\n",
      "          [-1.9235e-02,  3.0808e-02, -2.1943e-02]],\n",
      "\n",
      "         [[ 2.3963e-02, -1.4421e-02, -2.8244e-02],\n",
      "          [-3.7864e-02,  2.0384e-02,  4.1255e-03],\n",
      "          [-1.9360e-03,  2.8627e-02,  7.0025e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3974e-02, -3.6804e-02, -2.0411e-02],\n",
      "          [ 1.9338e-03,  1.6671e-02, -2.2251e-02],\n",
      "          [-3.2498e-02, -2.3095e-02, -1.7086e-02]],\n",
      "\n",
      "         [[-2.9996e-02,  4.0958e-02, -1.4566e-02],\n",
      "          [-1.8665e-02, -2.4553e-02,  8.4303e-03],\n",
      "          [ 4.1165e-02,  2.1262e-02,  3.7133e-02]],\n",
      "\n",
      "         [[ 8.2771e-03,  1.4452e-02,  2.2118e-03],\n",
      "          [ 1.1195e-02, -4.9368e-03, -2.0375e-02],\n",
      "          [ 5.6846e-03, -7.7862e-04, -2.7212e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9135e-02,  2.0752e-02,  7.9436e-03],\n",
      "          [ 2.7502e-02, -5.1691e-03, -3.3038e-02],\n",
      "          [ 5.3699e-03,  3.4598e-02, -2.6794e-02]],\n",
      "\n",
      "         [[ 3.0548e-02, -2.8727e-02, -2.4892e-02],\n",
      "          [-3.8073e-02,  3.5895e-02, -1.6745e-02],\n",
      "          [-5.6889e-05, -1.8122e-02,  3.3457e-02]],\n",
      "\n",
      "         [[ 1.1520e-02,  6.1168e-03, -1.5497e-02],\n",
      "          [-3.3231e-03, -2.2384e-02,  4.4887e-03],\n",
      "          [ 2.4497e-02, -3.6577e-02,  3.8162e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9383e-02,  3.5572e-02,  3.0361e-02],\n",
      "          [ 5.2571e-03, -1.9084e-02, -4.1557e-02],\n",
      "          [ 3.5408e-02,  3.7693e-02,  4.2172e-03]],\n",
      "\n",
      "         [[-5.9076e-04, -2.4707e-02,  3.8281e-02],\n",
      "          [ 3.7915e-02, -3.9129e-02, -1.5071e-02],\n",
      "          [ 2.6763e-02, -3.6381e-03, -8.2037e-03]],\n",
      "\n",
      "         [[-1.3659e-02,  9.3709e-03, -1.1886e-02],\n",
      "          [ 9.4851e-03,  2.6101e-03, -6.9711e-03],\n",
      "          [ 1.1749e-02, -1.1099e-02, -3.7763e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.8995e-02, -1.4276e-02, -1.3638e-02],\n",
      "          [ 1.8611e-02,  4.1182e-02,  2.4740e-02],\n",
      "          [-3.1450e-02,  9.1232e-03, -3.0759e-02]],\n",
      "\n",
      "         [[ 3.3693e-02, -2.4498e-02,  3.5756e-02],\n",
      "          [ 2.7887e-02, -2.7266e-02,  5.1399e-03],\n",
      "          [ 7.2076e-04,  2.9705e-02, -1.2516e-03]],\n",
      "\n",
      "         [[-2.4065e-02,  4.0313e-02,  1.1797e-02],\n",
      "          [ 1.1720e-02,  1.0017e-02, -2.0945e-02],\n",
      "          [-2.1405e-02,  1.8600e-02,  1.9361e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1294e-03,  1.9879e-02, -3.8999e-02],\n",
      "          [-1.1913e-02, -3.8740e-02,  6.2888e-03],\n",
      "          [-4.2951e-03,  2.0605e-02,  1.2058e-02]],\n",
      "\n",
      "         [[-3.3599e-02, -3.1169e-02, -3.1307e-02],\n",
      "          [ 3.5673e-02, -3.2389e-02,  1.7420e-02],\n",
      "          [ 2.0430e-02, -3.2101e-03,  2.4777e-03]],\n",
      "\n",
      "         [[ 4.4024e-03, -1.9553e-02,  3.9463e-02],\n",
      "          [-2.4723e-02, -1.6534e-02,  2.6077e-02],\n",
      "          [-1.7426e-02, -3.8240e-02, -1.4701e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9894e-02, -3.5411e-02, -3.1081e-02],\n",
      "          [ 1.3125e-03, -2.2144e-02,  1.9719e-02],\n",
      "          [ 8.9777e-03, -2.1864e-03,  4.4644e-03]],\n",
      "\n",
      "         [[-3.6740e-02,  3.3483e-02,  5.8988e-03],\n",
      "          [ 3.3530e-03,  2.3579e-02, -2.4786e-02],\n",
      "          [ 2.8825e-02, -2.6302e-02,  1.1399e-02]],\n",
      "\n",
      "         [[ 3.2536e-02, -8.7696e-03,  1.8184e-02],\n",
      "          [-3.0402e-02, -8.4886e-03, -2.1232e-02],\n",
      "          [ 8.0884e-03, -1.3887e-03, -1.4119e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0763e-02,  2.0201e-02,  1.4244e-02],\n",
      "          [-5.8302e-03, -2.4964e-02, -4.2201e-03],\n",
      "          [-1.2697e-02,  1.1849e-02, -1.6668e-02]],\n",
      "\n",
      "         [[ 1.7800e-02,  2.9264e-02, -2.7779e-02],\n",
      "          [-2.7842e-02,  2.1841e-02,  7.7532e-03],\n",
      "          [-7.7170e-03,  3.2372e-02,  1.3879e-02]],\n",
      "\n",
      "         [[ 4.6317e-03, -2.7629e-02,  2.3330e-02],\n",
      "          [ 3.9785e-03, -4.0161e-02, -2.8167e-02],\n",
      "          [ 2.8499e-02,  4.0928e-03, -3.8191e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3917e-02, -5.1038e-03,  1.0760e-02],\n",
      "          [-3.0983e-02,  3.4290e-02, -8.4794e-03],\n",
      "          [ 3.5742e-02, -1.7496e-02,  2.9554e-02]],\n",
      "\n",
      "         [[-1.5779e-02,  1.2107e-02, -1.2561e-03],\n",
      "          [ 3.7729e-02, -1.3588e-02,  2.6842e-02],\n",
      "          [ 1.2282e-02,  5.9187e-03,  3.2053e-02]],\n",
      "\n",
      "         [[ 2.0683e-02,  1.2413e-02, -3.4295e-02],\n",
      "          [-2.4512e-02,  3.0522e-02, -4.8837e-03],\n",
      "          [-3.5213e-02, -1.0895e-02, -1.1347e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.9722e-03, -2.6971e-02, -5.2001e-03],\n",
      "          [-2.1804e-02, -2.1454e-02,  2.4280e-02],\n",
      "          [-1.6157e-02, -1.8030e-02, -2.0757e-02]],\n",
      "\n",
      "         [[-3.9223e-03,  2.3701e-02, -2.3210e-03],\n",
      "          [ 1.2497e-02,  3.4894e-03,  3.6398e-02],\n",
      "          [ 3.9213e-02,  8.6516e-03, -1.6630e-02]],\n",
      "\n",
      "         [[-2.7015e-03,  1.1478e-02,  3.5990e-03],\n",
      "          [ 1.2411e-02, -3.0050e-02, -3.1527e-02],\n",
      "          [ 4.1424e-02,  4.8585e-03,  3.3720e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0395,  0.0322,  0.0162, -0.0055,  0.0401, -0.0067,  0.0162, -0.0248,\n",
      "        -0.0313, -0.0104,  0.0180,  0.0259, -0.0290, -0.0379,  0.0409, -0.0413,\n",
      "         0.0212,  0.0222,  0.0068,  0.0259, -0.0095,  0.0059,  0.0233,  0.0194,\n",
      "         0.0225,  0.0221,  0.0076,  0.0186,  0.0414,  0.0103, -0.0299,  0.0044,\n",
      "         0.0206,  0.0130,  0.0341, -0.0260, -0.0351,  0.0197,  0.0060,  0.0080,\n",
      "         0.0031, -0.0263, -0.0379, -0.0200,  0.0346, -0.0228, -0.0393,  0.0069,\n",
      "        -0.0379, -0.0369,  0.0269, -0.0277,  0.0042, -0.0231,  0.0307,  0.0096,\n",
      "        -0.0212, -0.0007, -0.0002,  0.0332,  0.0013,  0.0292, -0.0392, -0.0045],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0304, -0.0145, -0.0325],\n",
      "          [ 0.0244,  0.0073, -0.0224],\n",
      "          [ 0.0313,  0.0057,  0.0399]],\n",
      "\n",
      "         [[-0.0392, -0.0266, -0.0004],\n",
      "          [-0.0192,  0.0338,  0.0349],\n",
      "          [-0.0237, -0.0379,  0.0041]],\n",
      "\n",
      "         [[-0.0409,  0.0042, -0.0230],\n",
      "          [ 0.0220, -0.0244,  0.0045],\n",
      "          [-0.0177,  0.0291,  0.0360]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0306,  0.0240, -0.0289],\n",
      "          [ 0.0083,  0.0312, -0.0381],\n",
      "          [-0.0399, -0.0186,  0.0345]],\n",
      "\n",
      "         [[ 0.0182, -0.0284,  0.0385],\n",
      "          [-0.0300,  0.0301, -0.0060],\n",
      "          [ 0.0151,  0.0153,  0.0164]],\n",
      "\n",
      "         [[-0.0325,  0.0140, -0.0393],\n",
      "          [-0.0136, -0.0376,  0.0019],\n",
      "          [-0.0334, -0.0369,  0.0208]]],\n",
      "\n",
      "\n",
      "        [[[-0.0015, -0.0092,  0.0262],\n",
      "          [-0.0352, -0.0024,  0.0413],\n",
      "          [ 0.0315,  0.0250, -0.0097]],\n",
      "\n",
      "         [[-0.0033,  0.0284, -0.0276],\n",
      "          [ 0.0132,  0.0414,  0.0252],\n",
      "          [-0.0316,  0.0345,  0.0348]],\n",
      "\n",
      "         [[ 0.0204, -0.0310,  0.0115],\n",
      "          [ 0.0035,  0.0019, -0.0379],\n",
      "          [-0.0141, -0.0416,  0.0146]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0027, -0.0107, -0.0032],\n",
      "          [ 0.0057,  0.0359,  0.0017],\n",
      "          [-0.0082,  0.0189, -0.0382]],\n",
      "\n",
      "         [[ 0.0235,  0.0158,  0.0225],\n",
      "          [ 0.0004, -0.0199, -0.0276],\n",
      "          [ 0.0099,  0.0314, -0.0319]],\n",
      "\n",
      "         [[-0.0241,  0.0369,  0.0399],\n",
      "          [-0.0359, -0.0154, -0.0024],\n",
      "          [ 0.0163,  0.0003,  0.0003]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0128,  0.0366, -0.0108],\n",
      "          [ 0.0198, -0.0075, -0.0363],\n",
      "          [ 0.0225, -0.0124, -0.0225]],\n",
      "\n",
      "         [[ 0.0245,  0.0066,  0.0044],\n",
      "          [ 0.0160,  0.0157, -0.0284],\n",
      "          [-0.0317, -0.0387, -0.0413]],\n",
      "\n",
      "         [[-0.0273, -0.0142,  0.0284],\n",
      "          [-0.0223,  0.0100,  0.0234],\n",
      "          [-0.0203,  0.0059,  0.0365]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0249,  0.0313, -0.0062],\n",
      "          [-0.0046,  0.0152, -0.0032],\n",
      "          [ 0.0394,  0.0177,  0.0183]],\n",
      "\n",
      "         [[ 0.0105,  0.0098,  0.0143],\n",
      "          [ 0.0043, -0.0370, -0.0245],\n",
      "          [ 0.0200,  0.0116, -0.0123]],\n",
      "\n",
      "         [[-0.0294, -0.0205,  0.0139],\n",
      "          [-0.0332,  0.0335,  0.0333],\n",
      "          [ 0.0053, -0.0104, -0.0252]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0066,  0.0156,  0.0372],\n",
      "          [-0.0281,  0.0262, -0.0352],\n",
      "          [-0.0007, -0.0129,  0.0056]],\n",
      "\n",
      "         [[ 0.0378,  0.0112, -0.0185],\n",
      "          [-0.0012,  0.0156, -0.0014],\n",
      "          [ 0.0235, -0.0292, -0.0091]],\n",
      "\n",
      "         [[-0.0033, -0.0309, -0.0138],\n",
      "          [-0.0240,  0.0381, -0.0046],\n",
      "          [ 0.0063, -0.0334, -0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0150,  0.0181,  0.0366],\n",
      "          [-0.0070, -0.0312, -0.0205],\n",
      "          [ 0.0272,  0.0373, -0.0042]],\n",
      "\n",
      "         [[ 0.0313,  0.0047, -0.0397],\n",
      "          [-0.0053, -0.0131,  0.0337],\n",
      "          [ 0.0108,  0.0076,  0.0024]],\n",
      "\n",
      "         [[ 0.0104, -0.0116, -0.0081],\n",
      "          [-0.0002, -0.0412,  0.0141],\n",
      "          [-0.0065,  0.0300,  0.0008]]],\n",
      "\n",
      "\n",
      "        [[[-0.0041,  0.0221, -0.0207],\n",
      "          [ 0.0218,  0.0333, -0.0060],\n",
      "          [ 0.0332, -0.0013, -0.0252]],\n",
      "\n",
      "         [[-0.0303, -0.0109,  0.0179],\n",
      "          [ 0.0358,  0.0096,  0.0361],\n",
      "          [-0.0188,  0.0103, -0.0245]],\n",
      "\n",
      "         [[-0.0245,  0.0019, -0.0384],\n",
      "          [-0.0335, -0.0062,  0.0144],\n",
      "          [ 0.0004, -0.0323,  0.0244]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0327,  0.0112, -0.0119],\n",
      "          [-0.0269, -0.0060, -0.0293],\n",
      "          [ 0.0232, -0.0149,  0.0124]],\n",
      "\n",
      "         [[-0.0100, -0.0380, -0.0237],\n",
      "          [-0.0186,  0.0005,  0.0301],\n",
      "          [ 0.0281, -0.0042,  0.0278]],\n",
      "\n",
      "         [[-0.0404,  0.0232,  0.0043],\n",
      "          [-0.0076, -0.0326,  0.0386],\n",
      "          [-0.0328, -0.0357,  0.0154]]],\n",
      "\n",
      "\n",
      "        [[[-0.0296,  0.0289, -0.0341],\n",
      "          [-0.0167,  0.0019,  0.0192],\n",
      "          [-0.0218, -0.0248,  0.0270]],\n",
      "\n",
      "         [[-0.0114,  0.0255,  0.0002],\n",
      "          [ 0.0382, -0.0054, -0.0175],\n",
      "          [ 0.0227,  0.0340,  0.0381]],\n",
      "\n",
      "         [[ 0.0073,  0.0408, -0.0042],\n",
      "          [ 0.0175, -0.0170, -0.0043],\n",
      "          [ 0.0087, -0.0342,  0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0263, -0.0133, -0.0225],\n",
      "          [-0.0306,  0.0173,  0.0092],\n",
      "          [ 0.0224,  0.0064,  0.0008]],\n",
      "\n",
      "         [[-0.0059,  0.0319,  0.0206],\n",
      "          [-0.0349,  0.0269,  0.0245],\n",
      "          [ 0.0415,  0.0141, -0.0411]],\n",
      "\n",
      "         [[-0.0092,  0.0401, -0.0048],\n",
      "          [ 0.0116, -0.0073, -0.0327],\n",
      "          [-0.0363,  0.0083,  0.0104]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0166, -0.0381, -0.0043, -0.0337, -0.0384, -0.0106, -0.0061,  0.0321,\n",
      "        -0.0347, -0.0036, -0.0022,  0.0366,  0.0334, -0.0249, -0.0390, -0.0076,\n",
      "        -0.0369,  0.0146,  0.0049,  0.0354, -0.0096, -0.0157, -0.0048, -0.0235,\n",
      "        -0.0084,  0.0322,  0.0229,  0.0107, -0.0292,  0.0265, -0.0296, -0.0321,\n",
      "        -0.0290,  0.0283,  0.0347, -0.0280,  0.0416,  0.0345,  0.0205, -0.0240,\n",
      "        -0.0021, -0.0402, -0.0101,  0.0253,  0.0413, -0.0383,  0.0086, -0.0188,\n",
      "         0.0262,  0.0221,  0.0049, -0.0210,  0.0091,  0.0337, -0.0033,  0.0203,\n",
      "        -0.0062, -0.0099,  0.0349, -0.0410,  0.0200, -0.0195, -0.0003, -0.0333],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-1.9982e-02, -3.9725e-02, -3.8899e-02],\n",
      "          [ 6.1684e-03, -3.6883e-02,  3.6105e-02],\n",
      "          [-3.1963e-02, -2.0332e-02, -1.4034e-02]],\n",
      "\n",
      "         [[ 7.8589e-03,  4.1429e-02, -3.9654e-02],\n",
      "          [ 2.4156e-02,  3.1202e-03, -3.9159e-03],\n",
      "          [-3.2538e-02,  2.8815e-02, -3.2439e-02]],\n",
      "\n",
      "         [[-1.5833e-02, -9.4279e-03,  1.3458e-02],\n",
      "          [ 1.8243e-02,  3.1937e-02, -3.2560e-02],\n",
      "          [-2.2811e-02, -3.8484e-02,  2.7220e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4353e-02,  2.4609e-02, -8.1571e-03],\n",
      "          [-2.0917e-02, -1.1538e-02,  3.1185e-02],\n",
      "          [ 2.2156e-02,  3.5467e-02, -3.6269e-02]],\n",
      "\n",
      "         [[-2.0933e-02, -4.0497e-02,  3.0117e-02],\n",
      "          [ 1.0031e-03, -1.6316e-02,  3.1823e-02],\n",
      "          [ 6.8562e-03, -4.3866e-03, -3.5344e-02]],\n",
      "\n",
      "         [[ 4.0622e-02,  1.4547e-02, -4.9219e-05],\n",
      "          [-7.5529e-03,  1.5969e-02,  1.8871e-02],\n",
      "          [ 1.9470e-02, -3.4392e-02, -3.8485e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0744e-02,  1.5700e-02,  5.9227e-03],\n",
      "          [ 3.6773e-02,  5.2455e-03,  4.1642e-02],\n",
      "          [-3.7767e-02,  1.5742e-02,  3.2338e-02]],\n",
      "\n",
      "         [[ 3.3084e-02,  2.1187e-02,  4.1782e-03],\n",
      "          [ 2.6501e-02,  3.4408e-02,  2.0683e-02],\n",
      "          [-1.4361e-03,  3.9599e-02,  1.4607e-02]],\n",
      "\n",
      "         [[-4.3121e-03, -2.6927e-02,  1.4999e-02],\n",
      "          [ 8.8503e-03, -1.5875e-02,  3.7465e-02],\n",
      "          [ 2.3113e-02,  6.1879e-03,  1.8465e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7483e-02, -3.3464e-02, -2.1006e-02],\n",
      "          [-2.6896e-02, -4.2867e-03, -2.1057e-02],\n",
      "          [ 1.3569e-02, -9.3375e-03, -3.2317e-02]],\n",
      "\n",
      "         [[-2.9574e-02,  2.2819e-02,  4.6971e-03],\n",
      "          [ 3.2549e-02, -2.4813e-02, -1.6776e-02],\n",
      "          [ 5.1805e-04,  2.2879e-02, -1.1719e-02]],\n",
      "\n",
      "         [[-1.8016e-02,  3.1807e-02, -3.1352e-02],\n",
      "          [-9.7339e-03,  3.2209e-02,  4.1002e-02],\n",
      "          [-1.1149e-03, -3.0150e-02,  2.0974e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0608e-03, -3.1381e-03, -3.9339e-02],\n",
      "          [ 2.7538e-02,  1.9081e-02,  3.3121e-02],\n",
      "          [ 3.2777e-02, -2.6065e-02,  1.5223e-02]],\n",
      "\n",
      "         [[-2.5271e-02,  3.1774e-02,  2.3798e-02],\n",
      "          [ 2.4479e-02, -1.1341e-02, -3.7881e-02],\n",
      "          [-7.6354e-04,  3.6014e-02, -3.3636e-02]],\n",
      "\n",
      "         [[-3.8460e-02, -2.7443e-02,  1.7793e-02],\n",
      "          [-1.4754e-02, -3.9596e-02, -1.0433e-03],\n",
      "          [ 1.5699e-02,  2.7005e-02,  3.5851e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7199e-02, -2.5396e-02, -3.2714e-02],\n",
      "          [-1.7450e-02, -2.1622e-02,  2.3224e-02],\n",
      "          [-4.9174e-03,  3.5183e-02, -1.6677e-02]],\n",
      "\n",
      "         [[ 1.3491e-02,  9.3542e-03, -3.2725e-02],\n",
      "          [-1.9064e-02, -1.8689e-02,  3.4529e-02],\n",
      "          [ 3.1561e-02,  7.8281e-04,  5.7665e-03]],\n",
      "\n",
      "         [[-2.4455e-02,  3.4877e-02,  1.3577e-02],\n",
      "          [-5.6439e-03, -1.4751e-02, -3.8664e-02],\n",
      "          [ 1.2691e-02,  2.0994e-02,  3.4089e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3329e-02, -2.6177e-02,  4.0044e-02],\n",
      "          [ 3.8585e-02, -3.9881e-02,  9.7852e-03],\n",
      "          [ 2.2469e-02,  1.5998e-02,  3.8853e-02]],\n",
      "\n",
      "         [[ 2.1206e-02, -3.9349e-02, -1.0661e-02],\n",
      "          [-1.8955e-02, -1.9475e-02, -1.8314e-02],\n",
      "          [-2.0622e-02, -8.2282e-03,  2.7381e-02]],\n",
      "\n",
      "         [[-9.1181e-03,  2.0744e-02, -3.6061e-02],\n",
      "          [-2.2899e-02,  2.3835e-02,  3.7955e-02],\n",
      "          [ 3.9456e-02,  3.7118e-02,  1.6972e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1606e-02, -3.8496e-02, -2.8824e-02],\n",
      "          [-1.1160e-02, -3.7479e-03,  1.3896e-03],\n",
      "          [ 2.1123e-02,  6.0680e-03, -9.8039e-03]],\n",
      "\n",
      "         [[-2.6278e-02,  3.8440e-02, -3.6441e-02],\n",
      "          [-4.1065e-02,  1.9810e-02,  4.1384e-02],\n",
      "          [ 2.6948e-02, -3.7542e-02, -2.5129e-02]],\n",
      "\n",
      "         [[-1.0679e-03, -3.9704e-02, -4.0348e-02],\n",
      "          [ 2.3643e-02, -6.1728e-04, -9.8462e-03],\n",
      "          [ 2.1131e-02,  2.5168e-02, -3.0080e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3186e-02, -2.9568e-02, -3.6842e-02],\n",
      "          [-3.2133e-02,  2.9043e-02, -3.5908e-02],\n",
      "          [ 4.1152e-02,  1.9320e-02, -4.2343e-03]],\n",
      "\n",
      "         [[-2.1554e-02, -6.8490e-03, -2.0831e-02],\n",
      "          [ 3.6792e-02, -5.2844e-03,  2.9959e-02],\n",
      "          [ 5.1584e-03, -3.7014e-02, -8.5069e-03]],\n",
      "\n",
      "         [[ 3.3932e-02, -1.5857e-02,  4.0290e-02],\n",
      "          [-8.9148e-04, -1.1890e-02, -3.0553e-02],\n",
      "          [ 1.3106e-02,  1.4446e-02, -2.8366e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0733e-02, -7.0526e-03,  2.6500e-02],\n",
      "          [-1.8395e-02, -2.8225e-02,  1.9239e-02],\n",
      "          [ 1.6200e-02, -2.1013e-02, -7.2787e-03]],\n",
      "\n",
      "         [[-4.5112e-03, -2.4284e-02, -2.3810e-02],\n",
      "          [ 2.1409e-02, -1.4143e-02, -4.5077e-03],\n",
      "          [-2.0808e-02, -2.5905e-02,  5.1972e-04]],\n",
      "\n",
      "         [[ 2.5453e-02,  1.0453e-03, -1.5197e-02],\n",
      "          [ 2.8536e-02,  9.5682e-03, -1.4249e-02],\n",
      "          [-2.1673e-02,  3.3517e-02,  2.5071e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6274e-02, -1.8274e-03,  2.2195e-02],\n",
      "          [-3.9242e-02, -2.6047e-02,  3.2152e-02],\n",
      "          [ 3.7798e-02,  2.6034e-03, -1.1605e-03]],\n",
      "\n",
      "         [[-3.6156e-02, -2.7064e-02, -8.6997e-03],\n",
      "          [ 2.2546e-02, -3.3085e-02,  7.3288e-03],\n",
      "          [ 1.7441e-02, -9.1410e-03, -1.4159e-02]],\n",
      "\n",
      "         [[-1.1977e-02, -1.6765e-02, -3.7746e-02],\n",
      "          [ 3.2048e-02,  3.0754e-02,  8.0139e-03],\n",
      "          [-2.0674e-02,  1.2050e-02,  1.3567e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0935e-02,  2.0450e-02,  2.4666e-02],\n",
      "          [ 1.5512e-02, -3.2377e-02,  3.3219e-02],\n",
      "          [ 3.8202e-02, -1.6083e-02,  9.6351e-03]],\n",
      "\n",
      "         [[ 6.5982e-03, -8.4959e-03,  5.1555e-04],\n",
      "          [-2.2151e-02,  1.5857e-02, -2.7418e-02],\n",
      "          [-1.1737e-03, -2.7482e-02, -2.9330e-02]],\n",
      "\n",
      "         [[-3.7841e-02,  1.2915e-02, -1.0636e-02],\n",
      "          [ 2.7195e-02, -1.9293e-02, -2.9139e-03],\n",
      "          [ 2.1054e-02,  6.8875e-03,  3.3250e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0133, -0.0162, -0.0303,  0.0311,  0.0395, -0.0005, -0.0148, -0.0216,\n",
      "         0.0089,  0.0162,  0.0355,  0.0288,  0.0384,  0.0373, -0.0172,  0.0153,\n",
      "         0.0338, -0.0080, -0.0165,  0.0381, -0.0224,  0.0219,  0.0015, -0.0325,\n",
      "        -0.0104,  0.0236,  0.0137,  0.0290, -0.0258,  0.0148,  0.0373,  0.0401,\n",
      "         0.0057,  0.0044,  0.0220, -0.0290, -0.0142,  0.0128,  0.0008,  0.0144,\n",
      "         0.0078,  0.0155,  0.0027,  0.0384, -0.0010, -0.0340,  0.0212,  0.0170,\n",
      "         0.0251,  0.0324,  0.0351,  0.0172,  0.0341,  0.0165,  0.0121, -0.0213,\n",
      "        -0.0208,  0.0145,  0.0223, -0.0110,  0.0218,  0.0278, -0.0055, -0.0168],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.3976e-02, -2.2298e-02,  4.1014e-02,  ...,  2.9085e-02,\n",
      "         -2.5434e-02,  3.1472e-02],\n",
      "        [ 1.4059e-02, -8.5345e-04,  8.0341e-03,  ...,  3.6558e-02,\n",
      "          3.3003e-02,  2.5197e-02],\n",
      "        [-3.2516e-02, -2.7478e-05,  3.0782e-03,  ..., -7.3217e-03,\n",
      "          3.2358e-02,  4.0398e-02],\n",
      "        [ 2.5058e-02,  3.4104e-02,  6.7627e-03,  ..., -3.3432e-02,\n",
      "          2.8104e-02, -2.5581e-02],\n",
      "        [ 1.9341e-02,  1.6546e-02,  2.1527e-02,  ...,  3.0894e-02,\n",
      "          7.3708e-03, -3.0072e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import SineNetwork\n",
    "t = SineNetwork(criterion=nn.MSELoss())\n",
    "p = list(t.parameters())\n",
    "\n",
    "params = []\n",
    "for m in t.modules():\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        mparams = list(m.parameters())\n",
    "        for mp in mparams:\n",
    "            params.append(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.7171],\n",
      "        [-0.5224],\n",
      "        [-0.7895],\n",
      "        [ 0.6025],\n",
      "        [-0.0698],\n",
      "        [-0.4252],\n",
      "        [-0.1436],\n",
      "        [-0.4880],\n",
      "        [-0.7452],\n",
      "        [-0.9794],\n",
      "        [ 0.4532],\n",
      "        [-0.4506],\n",
      "        [ 0.4335],\n",
      "        [ 0.4047],\n",
      "        [ 0.7322],\n",
      "        [ 0.7659],\n",
      "        [-0.3939],\n",
      "        [-0.1875],\n",
      "        [-0.8394],\n",
      "        [ 0.2636],\n",
      "        [ 0.6228],\n",
      "        [-0.0882],\n",
      "        [-0.8235],\n",
      "        [-0.0806],\n",
      "        [-0.3454],\n",
      "        [-0.0769],\n",
      "        [-0.5211],\n",
      "        [-0.4694],\n",
      "        [-0.0099],\n",
      "        [ 0.4448],\n",
      "        [ 0.4228],\n",
      "        [ 0.4759],\n",
      "        [ 0.8949],\n",
      "        [ 0.2903],\n",
      "        [-0.6746],\n",
      "        [-0.9820],\n",
      "        [-0.5852],\n",
      "        [-0.9375],\n",
      "        [-0.9979],\n",
      "        [-0.7332]], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1202, -0.0637,  0.0176,  ..., -0.0031, -0.1008, -0.1458],\n",
      "        [-0.0872, -0.0326, -0.1333,  ..., -0.0929,  0.1105, -0.1032],\n",
      "        [ 0.0539,  0.0458,  0.0536,  ...,  0.0835, -0.1088,  0.1151],\n",
      "        ...,\n",
      "        [-0.0451,  0.0486, -0.1490,  ...,  0.0519,  0.0038,  0.0009],\n",
      "        [-0.0912,  0.0321,  0.1367,  ..., -0.0352,  0.0964,  0.0257],\n",
      "        [ 0.0288, -0.0010,  0.1514,  ...,  0.1403,  0.1421, -0.1548]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0051, -0.0433,  0.0478,  0.0748,  0.1508, -0.0279,  0.0570, -0.1046,\n",
      "         -0.0519,  0.0332,  0.0883,  0.0937, -0.0253, -0.1459, -0.0143,  0.0797,\n",
      "         -0.1515, -0.0607,  0.0812, -0.1574,  0.1190,  0.0489,  0.0151,  0.1015,\n",
      "         -0.1123,  0.1540, -0.0091,  0.0764, -0.0594,  0.0221, -0.0302,  0.0901,\n",
      "          0.1564,  0.0169, -0.0804,  0.1395,  0.1428,  0.0396, -0.0165, -0.0370]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ConvBlock(dev=\"cpu\", indim=3)\n",
    "p = list(t.parameters())\n",
    "\n",
    "params = []\n",
    "for m in t.modules():\n",
    "    if not isinstance(m, nn.BatchNorm2d):\n",
    "        mparams = list(m.parameters())\n",
    "        for mp in mparams:\n",
    "            params.append(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.1850, -0.0500, -0.0914],\n",
      "          [ 0.1236,  0.1912, -0.1587],\n",
      "          [ 0.0444,  0.0363, -0.1525]],\n",
      "\n",
      "         [[-0.1069,  0.0801,  0.0858],\n",
      "          [-0.1759, -0.1304,  0.0672],\n",
      "          [ 0.1066,  0.1135,  0.0793]],\n",
      "\n",
      "         [[-0.1773, -0.1359, -0.1550],\n",
      "          [-0.1924, -0.1824, -0.0155],\n",
      "          [-0.1159, -0.0340,  0.0940]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1636, -0.1293,  0.1100],\n",
      "          [-0.0121, -0.0992,  0.0275],\n",
      "          [ 0.1839,  0.0299,  0.0411]],\n",
      "\n",
      "         [[ 0.0284, -0.0869,  0.1329],\n",
      "          [-0.1277, -0.0059,  0.0665],\n",
      "          [ 0.1175, -0.0123, -0.1799]],\n",
      "\n",
      "         [[ 0.0060, -0.1788, -0.1741],\n",
      "          [-0.0754, -0.1593,  0.1731],\n",
      "          [-0.0497, -0.1917,  0.0820]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1430, -0.1345, -0.1812],\n",
      "          [ 0.1639, -0.0215, -0.0123],\n",
      "          [ 0.0885,  0.1593,  0.1607]],\n",
      "\n",
      "         [[-0.0057,  0.0293, -0.1199],\n",
      "          [-0.1707, -0.0687,  0.1878],\n",
      "          [-0.0867,  0.0350, -0.1182]],\n",
      "\n",
      "         [[-0.1760,  0.0216, -0.0889],\n",
      "          [ 0.1306,  0.0209, -0.0801],\n",
      "          [ 0.0933, -0.0324, -0.1723]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0641, -0.1349, -0.0523],\n",
      "          [ 0.1035, -0.0630, -0.1787],\n",
      "          [-0.1561,  0.1699, -0.0525]],\n",
      "\n",
      "         [[ 0.1053,  0.1773,  0.0328],\n",
      "          [ 0.1173,  0.1487,  0.1541],\n",
      "          [-0.0164,  0.0117, -0.1003]],\n",
      "\n",
      "         [[ 0.0252, -0.0516, -0.1035],\n",
      "          [ 0.1161, -0.0797, -0.0805],\n",
      "          [-0.1687,  0.0674,  0.1288]]],\n",
      "\n",
      "\n",
      "        [[[-0.1687, -0.1157, -0.1384],\n",
      "          [ 0.0691, -0.0698, -0.1830],\n",
      "          [-0.0463,  0.1406, -0.1111]],\n",
      "\n",
      "         [[ 0.1228,  0.1903, -0.1159],\n",
      "          [ 0.1577, -0.1567, -0.1488],\n",
      "          [ 0.0564, -0.1225,  0.1627]],\n",
      "\n",
      "         [[-0.1596,  0.0508,  0.1211],\n",
      "          [ 0.1818,  0.0499,  0.1379],\n",
      "          [ 0.0731, -0.1417,  0.0673]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0797, -0.1504, -0.1371],\n",
      "          [-0.0661, -0.1167, -0.0409],\n",
      "          [-0.0558,  0.0316,  0.1504]],\n",
      "\n",
      "         [[-0.0105,  0.1233, -0.0386],\n",
      "          [-0.1494, -0.1632, -0.0696],\n",
      "          [ 0.1082,  0.0991, -0.1559]],\n",
      "\n",
      "         [[ 0.0132,  0.1627, -0.1890],\n",
      "          [-0.0616,  0.1817,  0.0312],\n",
      "          [ 0.0493,  0.1117, -0.0332]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0223,  0.0032, -0.1076, -0.0713,  0.0010,  0.1024, -0.0573,  0.0813,\n",
      "         0.1545, -0.0057, -0.0616, -0.0111, -0.1710, -0.0631, -0.1354, -0.1288,\n",
      "        -0.1401,  0.0634, -0.0313, -0.0540,  0.0010,  0.1012, -0.0564, -0.0481,\n",
      "        -0.0605, -0.0040, -0.0740,  0.1376, -0.0509, -0.1130, -0.1780,  0.0545,\n",
      "        -0.1759, -0.0834,  0.0088,  0.0292,  0.0896, -0.1549, -0.1387,  0.0102,\n",
      "         0.0058,  0.1177,  0.1562, -0.1612, -0.0157, -0.1164,  0.1289, -0.0387,\n",
      "        -0.1047,  0.0013,  0.0099, -0.0751,  0.0022,  0.0573,  0.0661,  0.0211,\n",
      "         0.1395, -0.0582,  0.0668, -0.1717,  0.0142,  0.1418,  0.0623, -0.1065],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.1850, -0.0500, -0.0914],\n",
      "          [ 0.1236,  0.1912, -0.1587],\n",
      "          [ 0.0444,  0.0363, -0.1525]],\n",
      "\n",
      "         [[-0.1069,  0.0801,  0.0858],\n",
      "          [-0.1759, -0.1304,  0.0672],\n",
      "          [ 0.1066,  0.1135,  0.0793]],\n",
      "\n",
      "         [[-0.1773, -0.1359, -0.1550],\n",
      "          [-0.1924, -0.1824, -0.0155],\n",
      "          [-0.1159, -0.0340,  0.0940]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1636, -0.1293,  0.1100],\n",
      "          [-0.0121, -0.0992,  0.0275],\n",
      "          [ 0.1839,  0.0299,  0.0411]],\n",
      "\n",
      "         [[ 0.0284, -0.0869,  0.1329],\n",
      "          [-0.1277, -0.0059,  0.0665],\n",
      "          [ 0.1175, -0.0123, -0.1799]],\n",
      "\n",
      "         [[ 0.0060, -0.1788, -0.1741],\n",
      "          [-0.0754, -0.1593,  0.1731],\n",
      "          [-0.0497, -0.1917,  0.0820]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1430, -0.1345, -0.1812],\n",
      "          [ 0.1639, -0.0215, -0.0123],\n",
      "          [ 0.0885,  0.1593,  0.1607]],\n",
      "\n",
      "         [[-0.0057,  0.0293, -0.1199],\n",
      "          [-0.1707, -0.0687,  0.1878],\n",
      "          [-0.0867,  0.0350, -0.1182]],\n",
      "\n",
      "         [[-0.1760,  0.0216, -0.0889],\n",
      "          [ 0.1306,  0.0209, -0.0801],\n",
      "          [ 0.0933, -0.0324, -0.1723]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0641, -0.1349, -0.0523],\n",
      "          [ 0.1035, -0.0630, -0.1787],\n",
      "          [-0.1561,  0.1699, -0.0525]],\n",
      "\n",
      "         [[ 0.1053,  0.1773,  0.0328],\n",
      "          [ 0.1173,  0.1487,  0.1541],\n",
      "          [-0.0164,  0.0117, -0.1003]],\n",
      "\n",
      "         [[ 0.0252, -0.0516, -0.1035],\n",
      "          [ 0.1161, -0.0797, -0.0805],\n",
      "          [-0.1687,  0.0674,  0.1288]]],\n",
      "\n",
      "\n",
      "        [[[-0.1687, -0.1157, -0.1384],\n",
      "          [ 0.0691, -0.0698, -0.1830],\n",
      "          [-0.0463,  0.1406, -0.1111]],\n",
      "\n",
      "         [[ 0.1228,  0.1903, -0.1159],\n",
      "          [ 0.1577, -0.1567, -0.1488],\n",
      "          [ 0.0564, -0.1225,  0.1627]],\n",
      "\n",
      "         [[-0.1596,  0.0508,  0.1211],\n",
      "          [ 0.1818,  0.0499,  0.1379],\n",
      "          [ 0.0731, -0.1417,  0.0673]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0797, -0.1504, -0.1371],\n",
      "          [-0.0661, -0.1167, -0.0409],\n",
      "          [-0.0558,  0.0316,  0.1504]],\n",
      "\n",
      "         [[-0.0105,  0.1233, -0.0386],\n",
      "          [-0.1494, -0.1632, -0.0696],\n",
      "          [ 0.1082,  0.0991, -0.1559]],\n",
      "\n",
      "         [[ 0.0132,  0.1627, -0.1890],\n",
      "          [-0.0616,  0.1817,  0.0312],\n",
      "          [ 0.0493,  0.1117, -0.0332]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0223,  0.0032, -0.1076, -0.0713,  0.0010,  0.1024, -0.0573,  0.0813,\n",
      "         0.1545, -0.0057, -0.0616, -0.0111, -0.1710, -0.0631, -0.1354, -0.1288,\n",
      "        -0.1401,  0.0634, -0.0313, -0.0540,  0.0010,  0.1012, -0.0564, -0.0481,\n",
      "        -0.0605, -0.0040, -0.0740,  0.1376, -0.0509, -0.1130, -0.1780,  0.0545,\n",
      "        -0.1759, -0.0834,  0.0088,  0.0292,  0.0896, -0.1549, -0.1387,  0.0102,\n",
      "         0.0058,  0.1177,  0.1562, -0.1612, -0.0157, -0.1164,  0.1289, -0.0387,\n",
      "        -0.1047,  0.0013,  0.0099, -0.0751,  0.0022,  0.0573,  0.0661,  0.0211,\n",
      "         0.1395, -0.0582,  0.0668, -0.1717,  0.0142,  0.1418,  0.0623, -0.1065],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2.],\n",
       "         [3., 4.]]),\n",
       " tensor([[2., 3.],\n",
       "         [4., 5.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2],[3,4]])\n",
    "b = a.clone()\n",
    "b+=1 \n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Conv4(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleDict(\n",
      "  (features): Sequential(\n",
      "    (conv_block1): ConvBlock(\n",
      "      (cl): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv_block2): ConvBlock(\n",
      "      (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv_block3): ConvBlock(\n",
      "      (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv_block4): ConvBlock(\n",
      "      (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (flatten): Flatten()\n",
      "  )\n",
      "  (out): Linear(in_features=576, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ModuleDict' object has no attribute 'requires_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-abfbd98326ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n\\n\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/Metalearning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModuleDict' object has no attribute 'requires_grad'"
     ]
    }
   ],
   "source": [
    "for m in net.model.modules():\n",
    "    print(m,end='\\n\\n\\n\\n')\n",
    "    print(m.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "sd = net.state_dict()\n",
    "params = [p.clone() for p in net.parameters()]\n",
    "\n",
    "test = tuple([sd, params])\n",
    "with open(\"test.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.pkl\",\"rb\") as f:\n",
    "    sd2, params2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.features.conv_block1.cl.weight',\n",
       "              tensor([[[[-0.1623, -0.0017,  0.0474],\n",
       "                        [-0.0299, -0.1153, -0.1814],\n",
       "                        [ 0.0328,  0.0757, -0.1247]],\n",
       "              \n",
       "                       [[-0.0926,  0.0803,  0.0312],\n",
       "                        [-0.1704,  0.1027,  0.1454],\n",
       "                        [-0.0988,  0.0387,  0.0800]],\n",
       "              \n",
       "                       [[ 0.0039, -0.0360,  0.1487],\n",
       "                        [-0.0547,  0.1525,  0.1786],\n",
       "                        [-0.1867,  0.0908,  0.1110]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1720, -0.0133,  0.1300],\n",
       "                        [-0.1436, -0.1104, -0.0792],\n",
       "                        [-0.0509, -0.0066,  0.0674]],\n",
       "              \n",
       "                       [[ 0.0087,  0.0206,  0.0270],\n",
       "                        [-0.0970,  0.0400,  0.0800],\n",
       "                        [-0.1621,  0.1012,  0.1042]],\n",
       "              \n",
       "                       [[-0.1638,  0.0293,  0.0713],\n",
       "                        [ 0.1578,  0.1033,  0.0822],\n",
       "                        [-0.1699,  0.1017,  0.1795]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1901,  0.1152, -0.1482],\n",
       "                        [ 0.0663, -0.1590,  0.0401],\n",
       "                        [-0.0292, -0.1539, -0.1601]],\n",
       "              \n",
       "                       [[ 0.0139,  0.1563, -0.0862],\n",
       "                        [-0.1825, -0.1088,  0.0695],\n",
       "                        [-0.0366, -0.1760, -0.0197]],\n",
       "              \n",
       "                       [[-0.0721,  0.1476, -0.0823],\n",
       "                        [-0.0906,  0.0757, -0.1253],\n",
       "                        [-0.0314, -0.0129,  0.1761]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0092, -0.0724,  0.0079],\n",
       "                        [-0.1846,  0.0609, -0.0990],\n",
       "                        [-0.1812, -0.0003,  0.1095]],\n",
       "              \n",
       "                       [[ 0.0556,  0.1034,  0.0860],\n",
       "                        [-0.0683,  0.1477,  0.0785],\n",
       "                        [ 0.0538, -0.0146,  0.0169]],\n",
       "              \n",
       "                       [[ 0.1140,  0.1537,  0.1509],\n",
       "                        [ 0.0543, -0.1496,  0.0589],\n",
       "                        [ 0.1173,  0.0619, -0.1451]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1052, -0.0620, -0.0413],\n",
       "                        [-0.0037,  0.1811, -0.0876],\n",
       "                        [-0.0294, -0.1718, -0.0296]],\n",
       "              \n",
       "                       [[ 0.0218,  0.1147,  0.0902],\n",
       "                        [-0.0124, -0.1755, -0.1344],\n",
       "                        [-0.0112, -0.1311,  0.0306]],\n",
       "              \n",
       "                       [[-0.1071,  0.0281, -0.0552],\n",
       "                        [ 0.1287, -0.1738,  0.1219],\n",
       "                        [-0.0433, -0.1061,  0.0264]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1003,  0.1618,  0.0124],\n",
       "                        [-0.0923, -0.0875, -0.1918],\n",
       "                        [ 0.1647,  0.1815, -0.0043]],\n",
       "              \n",
       "                       [[ 0.0018,  0.1885, -0.0765],\n",
       "                        [-0.0617,  0.0443, -0.1316],\n",
       "                        [-0.1389,  0.0111,  0.1312]],\n",
       "              \n",
       "                       [[ 0.0216,  0.0490, -0.1049],\n",
       "                        [-0.1563,  0.1193,  0.1874],\n",
       "                        [-0.0201, -0.0811, -0.1108]]]])),\n",
       "             ('model.features.conv_block1.cl.bias',\n",
       "              tensor([-0.1394,  0.0061, -0.1372, -0.1611, -0.1246,  0.0576,  0.1232, -0.1770,\n",
       "                       0.0010,  0.0921,  0.0504,  0.0260, -0.1894, -0.1154,  0.1402, -0.1499,\n",
       "                      -0.0906,  0.0410,  0.0408, -0.1846,  0.0479, -0.0007, -0.1798, -0.0698,\n",
       "                      -0.1299,  0.0537, -0.0612,  0.0558, -0.0935,  0.1530,  0.1436,  0.1439,\n",
       "                       0.0437, -0.1780, -0.1611,  0.0609, -0.0946, -0.1132,  0.0526,  0.1230,\n",
       "                       0.1698, -0.1279, -0.0513,  0.0751, -0.0552, -0.1782,  0.0083,  0.0035,\n",
       "                       0.0197, -0.0966,  0.0559,  0.1427, -0.1002, -0.1715, -0.1534,  0.0060,\n",
       "                       0.1832, -0.1724,  0.1263, -0.1617,  0.1727, -0.0617, -0.1205, -0.0349])),\n",
       "             ('model.features.conv_block1.bn.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('model.features.conv_block1.bn.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('model.features.conv_block1.bn.running_mean',\n",
       "              tensor([-0.0265,  0.0013, -0.0263, -0.0306, -0.0237,  0.0110,  0.0238, -0.0341,\n",
       "                       0.0001,  0.0180,  0.0099,  0.0052, -0.0359, -0.0221,  0.0266, -0.0284,\n",
       "                      -0.0173,  0.0077,  0.0074, -0.0346,  0.0086, -0.0003, -0.0342, -0.0132,\n",
       "                      -0.0243,  0.0102, -0.0114,  0.0101, -0.0180,  0.0292,  0.0274,  0.0275,\n",
       "                       0.0086, -0.0340, -0.0309,  0.0114, -0.0177, -0.0215,  0.0100,  0.0234,\n",
       "                       0.0328, -0.0242, -0.0098,  0.0144, -0.0107, -0.0341,  0.0019,  0.0008,\n",
       "                       0.0038, -0.0186,  0.0108,  0.0272, -0.0194, -0.0327, -0.0292,  0.0011,\n",
       "                       0.0346, -0.0326,  0.0237, -0.0306,  0.0327, -0.0115, -0.0232, -0.0067])),\n",
       "             ('model.features.conv_block1.bn.running_var',\n",
       "              tensor([0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100])),\n",
       "             ('model.features.conv_block1.bn.num_batches_tracked', tensor(2)),\n",
       "             ('model.features.conv_block2.cl.weight',\n",
       "              tensor([[[[-3.7927e-02,  1.8433e-02,  1.1347e-02],\n",
       "                        [ 3.7656e-02,  8.7175e-03,  3.1939e-02],\n",
       "                        [-2.1264e-02,  2.5047e-02,  1.4723e-03]],\n",
       "              \n",
       "                       [[ 1.6700e-02, -3.6713e-03, -3.6093e-02],\n",
       "                        [ 2.6540e-02, -3.2410e-02, -2.7422e-03],\n",
       "                        [-4.8145e-03, -1.1295e-03,  3.8680e-02]],\n",
       "              \n",
       "                       [[-1.3997e-02,  3.4379e-02, -1.9653e-02],\n",
       "                        [ 3.5368e-02,  2.9425e-02,  5.5878e-04],\n",
       "                        [-1.1563e-02,  2.9978e-02, -1.6815e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.1353e-02, -7.7124e-03,  3.6018e-02],\n",
       "                        [-2.7176e-02, -5.1315e-03,  2.8327e-02],\n",
       "                        [-2.4774e-02,  7.4069e-03, -1.3264e-02]],\n",
       "              \n",
       "                       [[-2.7867e-02,  2.2814e-02, -3.2717e-02],\n",
       "                        [-1.0275e-02,  1.9114e-02, -3.2051e-02],\n",
       "                        [-6.8959e-03,  3.3153e-02,  2.8298e-03]],\n",
       "              \n",
       "                       [[-5.3128e-03,  1.4971e-02, -2.6541e-02],\n",
       "                        [-3.8398e-03, -1.4895e-02, -1.1782e-02],\n",
       "                        [ 4.1084e-02, -1.4202e-02,  2.3835e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7566e-02, -2.2950e-02, -1.2309e-02],\n",
       "                        [-1.8173e-04, -1.7255e-02, -5.2971e-03],\n",
       "                        [-3.7603e-02,  2.3253e-02, -8.5642e-03]],\n",
       "              \n",
       "                       [[-2.4765e-02,  2.5187e-02, -3.2083e-02],\n",
       "                        [ 9.9596e-04, -2.9622e-02,  6.6066e-04],\n",
       "                        [-1.9235e-02,  3.0808e-02, -2.1943e-02]],\n",
       "              \n",
       "                       [[ 2.3963e-02, -1.4421e-02, -2.8244e-02],\n",
       "                        [-3.7864e-02,  2.0384e-02,  4.1255e-03],\n",
       "                        [-1.9360e-03,  2.8627e-02,  7.0025e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3974e-02, -3.6804e-02, -2.0411e-02],\n",
       "                        [ 1.9338e-03,  1.6671e-02, -2.2251e-02],\n",
       "                        [-3.2498e-02, -2.3095e-02, -1.7086e-02]],\n",
       "              \n",
       "                       [[-2.9996e-02,  4.0958e-02, -1.4566e-02],\n",
       "                        [-1.8665e-02, -2.4553e-02,  8.4303e-03],\n",
       "                        [ 4.1165e-02,  2.1262e-02,  3.7133e-02]],\n",
       "              \n",
       "                       [[ 8.2771e-03,  1.4452e-02,  2.2118e-03],\n",
       "                        [ 1.1195e-02, -4.9368e-03, -2.0375e-02],\n",
       "                        [ 5.6846e-03, -7.7862e-04, -2.7212e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9135e-02,  2.0752e-02,  7.9436e-03],\n",
       "                        [ 2.7502e-02, -5.1691e-03, -3.3038e-02],\n",
       "                        [ 5.3699e-03,  3.4598e-02, -2.6794e-02]],\n",
       "              \n",
       "                       [[ 3.0548e-02, -2.8727e-02, -2.4892e-02],\n",
       "                        [-3.8073e-02,  3.5895e-02, -1.6745e-02],\n",
       "                        [-5.6889e-05, -1.8122e-02,  3.3457e-02]],\n",
       "              \n",
       "                       [[ 1.1520e-02,  6.1168e-03, -1.5497e-02],\n",
       "                        [-3.3231e-03, -2.2384e-02,  4.4887e-03],\n",
       "                        [ 2.4497e-02, -3.6577e-02,  3.8162e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9383e-02,  3.5572e-02,  3.0361e-02],\n",
       "                        [ 5.2571e-03, -1.9084e-02, -4.1557e-02],\n",
       "                        [ 3.5408e-02,  3.7693e-02,  4.2172e-03]],\n",
       "              \n",
       "                       [[-5.9076e-04, -2.4707e-02,  3.8281e-02],\n",
       "                        [ 3.7915e-02, -3.9129e-02, -1.5071e-02],\n",
       "                        [ 2.6763e-02, -3.6381e-03, -8.2037e-03]],\n",
       "              \n",
       "                       [[-1.3659e-02,  9.3709e-03, -1.1886e-02],\n",
       "                        [ 9.4851e-03,  2.6101e-03, -6.9711e-03],\n",
       "                        [ 1.1749e-02, -1.1099e-02, -3.7763e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8995e-02, -1.4276e-02, -1.3638e-02],\n",
       "                        [ 1.8611e-02,  4.1182e-02,  2.4740e-02],\n",
       "                        [-3.1450e-02,  9.1232e-03, -3.0759e-02]],\n",
       "              \n",
       "                       [[ 3.3693e-02, -2.4498e-02,  3.5756e-02],\n",
       "                        [ 2.7887e-02, -2.7266e-02,  5.1399e-03],\n",
       "                        [ 7.2076e-04,  2.9705e-02, -1.2516e-03]],\n",
       "              \n",
       "                       [[-2.4065e-02,  4.0313e-02,  1.1797e-02],\n",
       "                        [ 1.1720e-02,  1.0017e-02, -2.0945e-02],\n",
       "                        [-2.1405e-02,  1.8600e-02,  1.9361e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.1294e-03,  1.9879e-02, -3.8999e-02],\n",
       "                        [-1.1913e-02, -3.8740e-02,  6.2888e-03],\n",
       "                        [-4.2951e-03,  2.0605e-02,  1.2058e-02]],\n",
       "              \n",
       "                       [[-3.3599e-02, -3.1169e-02, -3.1307e-02],\n",
       "                        [ 3.5673e-02, -3.2389e-02,  1.7420e-02],\n",
       "                        [ 2.0430e-02, -3.2101e-03,  2.4777e-03]],\n",
       "              \n",
       "                       [[ 4.4024e-03, -1.9553e-02,  3.9463e-02],\n",
       "                        [-2.4723e-02, -1.6534e-02,  2.6077e-02],\n",
       "                        [-1.7426e-02, -3.8240e-02, -1.4701e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9894e-02, -3.5411e-02, -3.1081e-02],\n",
       "                        [ 1.3125e-03, -2.2144e-02,  1.9719e-02],\n",
       "                        [ 8.9777e-03, -2.1864e-03,  4.4644e-03]],\n",
       "              \n",
       "                       [[-3.6740e-02,  3.3483e-02,  5.8988e-03],\n",
       "                        [ 3.3530e-03,  2.3579e-02, -2.4786e-02],\n",
       "                        [ 2.8825e-02, -2.6302e-02,  1.1399e-02]],\n",
       "              \n",
       "                       [[ 3.2536e-02, -8.7696e-03,  1.8184e-02],\n",
       "                        [-3.0402e-02, -8.4886e-03, -2.1232e-02],\n",
       "                        [ 8.0884e-03, -1.3887e-03, -1.4119e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0763e-02,  2.0201e-02,  1.4244e-02],\n",
       "                        [-5.8302e-03, -2.4964e-02, -4.2201e-03],\n",
       "                        [-1.2697e-02,  1.1849e-02, -1.6668e-02]],\n",
       "              \n",
       "                       [[ 1.7800e-02,  2.9264e-02, -2.7779e-02],\n",
       "                        [-2.7842e-02,  2.1841e-02,  7.7532e-03],\n",
       "                        [-7.7170e-03,  3.2372e-02,  1.3879e-02]],\n",
       "              \n",
       "                       [[ 4.6317e-03, -2.7629e-02,  2.3330e-02],\n",
       "                        [ 3.9785e-03, -4.0161e-02, -2.8167e-02],\n",
       "                        [ 2.8499e-02,  4.0928e-03, -3.8191e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3917e-02, -5.1038e-03,  1.0760e-02],\n",
       "                        [-3.0983e-02,  3.4290e-02, -8.4794e-03],\n",
       "                        [ 3.5742e-02, -1.7496e-02,  2.9554e-02]],\n",
       "              \n",
       "                       [[-1.5779e-02,  1.2107e-02, -1.2561e-03],\n",
       "                        [ 3.7729e-02, -1.3588e-02,  2.6842e-02],\n",
       "                        [ 1.2282e-02,  5.9187e-03,  3.2053e-02]],\n",
       "              \n",
       "                       [[ 2.0683e-02,  1.2413e-02, -3.4295e-02],\n",
       "                        [-2.4512e-02,  3.0522e-02, -4.8837e-03],\n",
       "                        [-3.5213e-02, -1.0895e-02, -1.1347e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.9722e-03, -2.6971e-02, -5.2001e-03],\n",
       "                        [-2.1804e-02, -2.1454e-02,  2.4280e-02],\n",
       "                        [-1.6157e-02, -1.8030e-02, -2.0757e-02]],\n",
       "              \n",
       "                       [[-3.9223e-03,  2.3701e-02, -2.3210e-03],\n",
       "                        [ 1.2497e-02,  3.4894e-03,  3.6398e-02],\n",
       "                        [ 3.9213e-02,  8.6516e-03, -1.6630e-02]],\n",
       "              \n",
       "                       [[-2.7015e-03,  1.1478e-02,  3.5990e-03],\n",
       "                        [ 1.2411e-02, -3.0050e-02, -3.1527e-02],\n",
       "                        [ 4.1424e-02,  4.8585e-03,  3.3720e-02]]]])),\n",
       "             ('model.features.conv_block2.cl.bias',\n",
       "              tensor([ 0.0395,  0.0322,  0.0162, -0.0055,  0.0401, -0.0067,  0.0162, -0.0248,\n",
       "                      -0.0313, -0.0104,  0.0180,  0.0259, -0.0290, -0.0379,  0.0409, -0.0413,\n",
       "                       0.0212,  0.0222,  0.0068,  0.0259, -0.0095,  0.0059,  0.0233,  0.0194,\n",
       "                       0.0225,  0.0221,  0.0076,  0.0186,  0.0414,  0.0103, -0.0299,  0.0044,\n",
       "                       0.0206,  0.0130,  0.0341, -0.0260, -0.0351,  0.0197,  0.0060,  0.0080,\n",
       "                       0.0031, -0.0263, -0.0379, -0.0200,  0.0346, -0.0228, -0.0393,  0.0069,\n",
       "                      -0.0379, -0.0369,  0.0269, -0.0277,  0.0042, -0.0231,  0.0307,  0.0096,\n",
       "                      -0.0212, -0.0007, -0.0002,  0.0332,  0.0013,  0.0292, -0.0392, -0.0045])),\n",
       "             ('model.features.conv_block2.bn.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('model.features.conv_block2.bn.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('model.features.conv_block2.bn.running_mean',\n",
       "              tensor([-0.0021,  0.0094,  0.0385, -0.0359,  0.0144,  0.0270,  0.0330,  0.0333,\n",
       "                       0.0143, -0.0013, -0.0122, -0.0016, -0.0063,  0.0036, -0.0169,  0.0104,\n",
       "                       0.0050, -0.0166,  0.0004, -0.0071, -0.0263,  0.0117,  0.0181, -0.0135,\n",
       "                       0.0349,  0.0202,  0.0007, -0.0133,  0.0122, -0.0299, -0.0439, -0.0481,\n",
       "                      -0.0273,  0.0106,  0.0396, -0.0233,  0.0124,  0.0267, -0.0064, -0.0118,\n",
       "                       0.0056, -0.0185, -0.0078, -0.0217, -0.0377,  0.0181,  0.0375, -0.0269,\n",
       "                       0.0141,  0.0215,  0.0199, -0.0090,  0.0263,  0.0379, -0.0103, -0.0199,\n",
       "                      -0.0241, -0.0033,  0.0412, -0.0304,  0.0062, -0.0213, -0.0357, -0.0234])),\n",
       "             ('model.features.conv_block2.bn.running_var',\n",
       "              tensor([0.8115, 0.8111, 0.8113, 0.8109, 0.8111, 0.8112, 0.8112, 0.8110, 0.8112,\n",
       "                      0.8114, 0.8110, 0.8114, 0.8112, 0.8112, 0.8112, 0.8114, 0.8112, 0.8111,\n",
       "                      0.8114, 0.8114, 0.8111, 0.8113, 0.8111, 0.8110, 0.8113, 0.8112, 0.8115,\n",
       "                      0.8110, 0.8113, 0.8112, 0.8112, 0.8112, 0.8111, 0.8112, 0.8111, 0.8110,\n",
       "                      0.8112, 0.8112, 0.8111, 0.8114, 0.8112, 0.8112, 0.8112, 0.8109, 0.8114,\n",
       "                      0.8111, 0.8109, 0.8111, 0.8111, 0.8112, 0.8111, 0.8112, 0.8113, 0.8111,\n",
       "                      0.8111, 0.8110, 0.8111, 0.8111, 0.8116, 0.8112, 0.8113, 0.8113, 0.8112,\n",
       "                      0.8114])),\n",
       "             ('model.features.conv_block2.bn.num_batches_tracked', tensor(2)),\n",
       "             ('model.features.conv_block3.cl.weight',\n",
       "              tensor([[[[ 0.0304, -0.0145, -0.0325],\n",
       "                        [ 0.0244,  0.0073, -0.0224],\n",
       "                        [ 0.0313,  0.0057,  0.0399]],\n",
       "              \n",
       "                       [[-0.0392, -0.0266, -0.0004],\n",
       "                        [-0.0192,  0.0338,  0.0349],\n",
       "                        [-0.0237, -0.0379,  0.0041]],\n",
       "              \n",
       "                       [[-0.0409,  0.0042, -0.0230],\n",
       "                        [ 0.0220, -0.0244,  0.0045],\n",
       "                        [-0.0177,  0.0291,  0.0360]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0306,  0.0240, -0.0289],\n",
       "                        [ 0.0083,  0.0312, -0.0381],\n",
       "                        [-0.0399, -0.0186,  0.0345]],\n",
       "              \n",
       "                       [[ 0.0182, -0.0284,  0.0385],\n",
       "                        [-0.0300,  0.0301, -0.0060],\n",
       "                        [ 0.0151,  0.0153,  0.0164]],\n",
       "              \n",
       "                       [[-0.0325,  0.0140, -0.0393],\n",
       "                        [-0.0136, -0.0376,  0.0019],\n",
       "                        [-0.0334, -0.0369,  0.0208]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0015, -0.0092,  0.0262],\n",
       "                        [-0.0352, -0.0024,  0.0413],\n",
       "                        [ 0.0315,  0.0250, -0.0097]],\n",
       "              \n",
       "                       [[-0.0033,  0.0284, -0.0276],\n",
       "                        [ 0.0132,  0.0414,  0.0252],\n",
       "                        [-0.0316,  0.0345,  0.0348]],\n",
       "              \n",
       "                       [[ 0.0204, -0.0310,  0.0115],\n",
       "                        [ 0.0035,  0.0019, -0.0379],\n",
       "                        [-0.0141, -0.0416,  0.0146]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0027, -0.0107, -0.0032],\n",
       "                        [ 0.0057,  0.0359,  0.0017],\n",
       "                        [-0.0082,  0.0189, -0.0382]],\n",
       "              \n",
       "                       [[ 0.0235,  0.0158,  0.0225],\n",
       "                        [ 0.0004, -0.0199, -0.0276],\n",
       "                        [ 0.0099,  0.0314, -0.0319]],\n",
       "              \n",
       "                       [[-0.0241,  0.0369,  0.0399],\n",
       "                        [-0.0359, -0.0154, -0.0024],\n",
       "                        [ 0.0163,  0.0003,  0.0003]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0128,  0.0366, -0.0108],\n",
       "                        [ 0.0198, -0.0075, -0.0363],\n",
       "                        [ 0.0225, -0.0124, -0.0225]],\n",
       "              \n",
       "                       [[ 0.0245,  0.0066,  0.0044],\n",
       "                        [ 0.0160,  0.0157, -0.0284],\n",
       "                        [-0.0317, -0.0387, -0.0413]],\n",
       "              \n",
       "                       [[-0.0273, -0.0142,  0.0284],\n",
       "                        [-0.0223,  0.0100,  0.0234],\n",
       "                        [-0.0203,  0.0059,  0.0365]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0249,  0.0313, -0.0062],\n",
       "                        [-0.0046,  0.0152, -0.0032],\n",
       "                        [ 0.0394,  0.0177,  0.0183]],\n",
       "              \n",
       "                       [[ 0.0105,  0.0098,  0.0143],\n",
       "                        [ 0.0043, -0.0370, -0.0245],\n",
       "                        [ 0.0200,  0.0116, -0.0123]],\n",
       "              \n",
       "                       [[-0.0294, -0.0205,  0.0139],\n",
       "                        [-0.0332,  0.0335,  0.0333],\n",
       "                        [ 0.0053, -0.0104, -0.0252]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0066,  0.0156,  0.0372],\n",
       "                        [-0.0281,  0.0262, -0.0352],\n",
       "                        [-0.0007, -0.0129,  0.0056]],\n",
       "              \n",
       "                       [[ 0.0378,  0.0112, -0.0185],\n",
       "                        [-0.0012,  0.0156, -0.0014],\n",
       "                        [ 0.0235, -0.0292, -0.0091]],\n",
       "              \n",
       "                       [[-0.0033, -0.0309, -0.0138],\n",
       "                        [-0.0240,  0.0381, -0.0046],\n",
       "                        [ 0.0063, -0.0334, -0.0354]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0150,  0.0181,  0.0366],\n",
       "                        [-0.0070, -0.0312, -0.0205],\n",
       "                        [ 0.0272,  0.0373, -0.0042]],\n",
       "              \n",
       "                       [[ 0.0313,  0.0047, -0.0397],\n",
       "                        [-0.0053, -0.0131,  0.0337],\n",
       "                        [ 0.0108,  0.0076,  0.0024]],\n",
       "              \n",
       "                       [[ 0.0104, -0.0116, -0.0081],\n",
       "                        [-0.0002, -0.0412,  0.0141],\n",
       "                        [-0.0065,  0.0300,  0.0008]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0041,  0.0221, -0.0207],\n",
       "                        [ 0.0218,  0.0333, -0.0060],\n",
       "                        [ 0.0332, -0.0013, -0.0252]],\n",
       "              \n",
       "                       [[-0.0303, -0.0109,  0.0179],\n",
       "                        [ 0.0358,  0.0096,  0.0361],\n",
       "                        [-0.0188,  0.0103, -0.0245]],\n",
       "              \n",
       "                       [[-0.0245,  0.0019, -0.0384],\n",
       "                        [-0.0335, -0.0062,  0.0144],\n",
       "                        [ 0.0004, -0.0323,  0.0244]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0327,  0.0112, -0.0119],\n",
       "                        [-0.0269, -0.0060, -0.0293],\n",
       "                        [ 0.0232, -0.0149,  0.0124]],\n",
       "              \n",
       "                       [[-0.0100, -0.0380, -0.0237],\n",
       "                        [-0.0186,  0.0005,  0.0301],\n",
       "                        [ 0.0281, -0.0042,  0.0278]],\n",
       "              \n",
       "                       [[-0.0404,  0.0232,  0.0043],\n",
       "                        [-0.0076, -0.0326,  0.0386],\n",
       "                        [-0.0328, -0.0357,  0.0154]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0296,  0.0289, -0.0341],\n",
       "                        [-0.0167,  0.0019,  0.0192],\n",
       "                        [-0.0218, -0.0248,  0.0270]],\n",
       "              \n",
       "                       [[-0.0114,  0.0255,  0.0002],\n",
       "                        [ 0.0382, -0.0054, -0.0175],\n",
       "                        [ 0.0227,  0.0340,  0.0381]],\n",
       "              \n",
       "                       [[ 0.0073,  0.0408, -0.0042],\n",
       "                        [ 0.0175, -0.0170, -0.0043],\n",
       "                        [ 0.0087, -0.0342,  0.0092]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0263, -0.0133, -0.0225],\n",
       "                        [-0.0306,  0.0173,  0.0092],\n",
       "                        [ 0.0224,  0.0064,  0.0008]],\n",
       "              \n",
       "                       [[-0.0059,  0.0319,  0.0206],\n",
       "                        [-0.0349,  0.0269,  0.0245],\n",
       "                        [ 0.0415,  0.0141, -0.0411]],\n",
       "              \n",
       "                       [[-0.0092,  0.0401, -0.0048],\n",
       "                        [ 0.0116, -0.0073, -0.0327],\n",
       "                        [-0.0363,  0.0083,  0.0104]]]])),\n",
       "             ('model.features.conv_block3.cl.bias',\n",
       "              tensor([-0.0166, -0.0381, -0.0043, -0.0337, -0.0384, -0.0106, -0.0061,  0.0321,\n",
       "                      -0.0347, -0.0036, -0.0022,  0.0366,  0.0334, -0.0249, -0.0390, -0.0076,\n",
       "                      -0.0369,  0.0146,  0.0049,  0.0354, -0.0096, -0.0157, -0.0048, -0.0235,\n",
       "                      -0.0084,  0.0322,  0.0229,  0.0107, -0.0292,  0.0265, -0.0296, -0.0321,\n",
       "                      -0.0290,  0.0283,  0.0347, -0.0280,  0.0416,  0.0345,  0.0205, -0.0240,\n",
       "                      -0.0021, -0.0402, -0.0101,  0.0253,  0.0413, -0.0383,  0.0086, -0.0188,\n",
       "                       0.0262,  0.0221,  0.0049, -0.0210,  0.0091,  0.0337, -0.0033,  0.0203,\n",
       "                      -0.0062, -0.0099,  0.0349, -0.0410,  0.0200, -0.0195, -0.0003, -0.0333])),\n",
       "             ('model.features.conv_block3.bn.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('model.features.conv_block3.bn.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('model.features.conv_block3.bn.running_mean',\n",
       "              tensor([-0.0174,  0.0611, -0.0577,  0.0472, -0.2896,  0.1669, -0.1291, -0.1750,\n",
       "                       0.0447, -0.1903,  0.1447,  0.0180,  0.1067,  0.0847,  0.0491, -0.0032,\n",
       "                       0.0042,  0.1980,  0.0532, -0.0444,  0.2035,  0.0686, -0.0896,  0.1867,\n",
       "                       0.0896, -0.1201,  0.2195,  0.0201, -0.0375, -0.0218,  0.0923,  0.2247,\n",
       "                       0.0849, -0.0648, -0.1735,  0.0112,  0.0023,  0.0930,  0.1376, -0.2941,\n",
       "                       0.1051, -0.1022,  0.0859, -0.0852,  0.0136,  0.1057,  0.0477,  0.0911,\n",
       "                       0.1628,  0.0347, -0.1101, -0.0879,  0.0058, -0.2478, -0.0663,  0.0889,\n",
       "                       0.1393,  0.0789, -0.0208,  0.0055,  0.1028, -0.0324,  0.0424, -0.0301])),\n",
       "             ('model.features.conv_block3.bn.running_var',\n",
       "              tensor([0.8382, 0.8361, 0.8378, 0.8368, 0.8366, 0.8368, 0.8382, 0.8396, 0.8376,\n",
       "                      0.8392, 0.8371, 0.8400, 0.8374, 0.8370, 0.8398, 0.8392, 0.8382, 0.8384,\n",
       "                      0.8382, 0.8353, 0.8425, 0.8362, 0.8365, 0.8387, 0.8385, 0.8376, 0.8388,\n",
       "                      0.8411, 0.8377, 0.8393, 0.8409, 0.8379, 0.8369, 0.8367, 0.8360, 0.8372,\n",
       "                      0.8388, 0.8409, 0.8369, 0.8377, 0.8395, 0.8391, 0.8413, 0.8376, 0.8367,\n",
       "                      0.8361, 0.8389, 0.8379, 0.8385, 0.8357, 0.8391, 0.8394, 0.8373, 0.8353,\n",
       "                      0.8389, 0.8377, 0.8414, 0.8401, 0.8374, 0.8382, 0.8414, 0.8391, 0.8358,\n",
       "                      0.8388])),\n",
       "             ('model.features.conv_block3.bn.num_batches_tracked', tensor(2)),\n",
       "             ('model.features.conv_block4.cl.weight',\n",
       "              tensor([[[[-1.9982e-02, -3.9725e-02, -3.8899e-02],\n",
       "                        [ 6.1684e-03, -3.6883e-02,  3.6105e-02],\n",
       "                        [-3.1963e-02, -2.0332e-02, -1.4034e-02]],\n",
       "              \n",
       "                       [[ 7.8589e-03,  4.1429e-02, -3.9654e-02],\n",
       "                        [ 2.4156e-02,  3.1202e-03, -3.9159e-03],\n",
       "                        [-3.2538e-02,  2.8815e-02, -3.2439e-02]],\n",
       "              \n",
       "                       [[-1.5833e-02, -9.4279e-03,  1.3458e-02],\n",
       "                        [ 1.8243e-02,  3.1937e-02, -3.2560e-02],\n",
       "                        [-2.2811e-02, -3.8484e-02,  2.7220e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4353e-02,  2.4609e-02, -8.1571e-03],\n",
       "                        [-2.0917e-02, -1.1538e-02,  3.1185e-02],\n",
       "                        [ 2.2156e-02,  3.5467e-02, -3.6269e-02]],\n",
       "              \n",
       "                       [[-2.0933e-02, -4.0497e-02,  3.0117e-02],\n",
       "                        [ 1.0031e-03, -1.6316e-02,  3.1823e-02],\n",
       "                        [ 6.8562e-03, -4.3866e-03, -3.5344e-02]],\n",
       "              \n",
       "                       [[ 4.0622e-02,  1.4547e-02, -4.9219e-05],\n",
       "                        [-7.5529e-03,  1.5969e-02,  1.8871e-02],\n",
       "                        [ 1.9470e-02, -3.4392e-02, -3.8485e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0744e-02,  1.5700e-02,  5.9227e-03],\n",
       "                        [ 3.6773e-02,  5.2455e-03,  4.1642e-02],\n",
       "                        [-3.7767e-02,  1.5742e-02,  3.2338e-02]],\n",
       "              \n",
       "                       [[ 3.3084e-02,  2.1187e-02,  4.1782e-03],\n",
       "                        [ 2.6501e-02,  3.4408e-02,  2.0683e-02],\n",
       "                        [-1.4361e-03,  3.9599e-02,  1.4607e-02]],\n",
       "              \n",
       "                       [[-4.3121e-03, -2.6927e-02,  1.4999e-02],\n",
       "                        [ 8.8503e-03, -1.5875e-02,  3.7465e-02],\n",
       "                        [ 2.3113e-02,  6.1879e-03,  1.8465e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7483e-02, -3.3464e-02, -2.1006e-02],\n",
       "                        [-2.6896e-02, -4.2867e-03, -2.1057e-02],\n",
       "                        [ 1.3569e-02, -9.3375e-03, -3.2317e-02]],\n",
       "              \n",
       "                       [[-2.9574e-02,  2.2819e-02,  4.6971e-03],\n",
       "                        [ 3.2549e-02, -2.4813e-02, -1.6776e-02],\n",
       "                        [ 5.1805e-04,  2.2879e-02, -1.1719e-02]],\n",
       "              \n",
       "                       [[-1.8016e-02,  3.1807e-02, -3.1352e-02],\n",
       "                        [-9.7339e-03,  3.2209e-02,  4.1002e-02],\n",
       "                        [-1.1149e-03, -3.0150e-02,  2.0974e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0608e-03, -3.1381e-03, -3.9339e-02],\n",
       "                        [ 2.7538e-02,  1.9081e-02,  3.3121e-02],\n",
       "                        [ 3.2777e-02, -2.6065e-02,  1.5223e-02]],\n",
       "              \n",
       "                       [[-2.5271e-02,  3.1774e-02,  2.3798e-02],\n",
       "                        [ 2.4479e-02, -1.1341e-02, -3.7881e-02],\n",
       "                        [-7.6354e-04,  3.6014e-02, -3.3636e-02]],\n",
       "              \n",
       "                       [[-3.8460e-02, -2.7443e-02,  1.7793e-02],\n",
       "                        [-1.4754e-02, -3.9596e-02, -1.0433e-03],\n",
       "                        [ 1.5699e-02,  2.7005e-02,  3.5851e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.7199e-02, -2.5396e-02, -3.2714e-02],\n",
       "                        [-1.7450e-02, -2.1622e-02,  2.3224e-02],\n",
       "                        [-4.9174e-03,  3.5183e-02, -1.6677e-02]],\n",
       "              \n",
       "                       [[ 1.3491e-02,  9.3542e-03, -3.2725e-02],\n",
       "                        [-1.9064e-02, -1.8689e-02,  3.4529e-02],\n",
       "                        [ 3.1561e-02,  7.8281e-04,  5.7665e-03]],\n",
       "              \n",
       "                       [[-2.4455e-02,  3.4877e-02,  1.3577e-02],\n",
       "                        [-5.6439e-03, -1.4751e-02, -3.8664e-02],\n",
       "                        [ 1.2691e-02,  2.0994e-02,  3.4089e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.3329e-02, -2.6177e-02,  4.0044e-02],\n",
       "                        [ 3.8585e-02, -3.9881e-02,  9.7852e-03],\n",
       "                        [ 2.2469e-02,  1.5998e-02,  3.8853e-02]],\n",
       "              \n",
       "                       [[ 2.1206e-02, -3.9349e-02, -1.0661e-02],\n",
       "                        [-1.8955e-02, -1.9475e-02, -1.8314e-02],\n",
       "                        [-2.0622e-02, -8.2282e-03,  2.7381e-02]],\n",
       "              \n",
       "                       [[-9.1181e-03,  2.0744e-02, -3.6061e-02],\n",
       "                        [-2.2899e-02,  2.3835e-02,  3.7955e-02],\n",
       "                        [ 3.9456e-02,  3.7118e-02,  1.6972e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.1606e-02, -3.8496e-02, -2.8824e-02],\n",
       "                        [-1.1160e-02, -3.7479e-03,  1.3896e-03],\n",
       "                        [ 2.1123e-02,  6.0680e-03, -9.8039e-03]],\n",
       "              \n",
       "                       [[-2.6278e-02,  3.8440e-02, -3.6441e-02],\n",
       "                        [-4.1065e-02,  1.9810e-02,  4.1384e-02],\n",
       "                        [ 2.6948e-02, -3.7542e-02, -2.5129e-02]],\n",
       "              \n",
       "                       [[-1.0679e-03, -3.9704e-02, -4.0348e-02],\n",
       "                        [ 2.3643e-02, -6.1728e-04, -9.8462e-03],\n",
       "                        [ 2.1131e-02,  2.5168e-02, -3.0080e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3186e-02, -2.9568e-02, -3.6842e-02],\n",
       "                        [-3.2133e-02,  2.9043e-02, -3.5908e-02],\n",
       "                        [ 4.1152e-02,  1.9320e-02, -4.2343e-03]],\n",
       "              \n",
       "                       [[-2.1554e-02, -6.8490e-03, -2.0831e-02],\n",
       "                        [ 3.6792e-02, -5.2844e-03,  2.9959e-02],\n",
       "                        [ 5.1584e-03, -3.7014e-02, -8.5069e-03]],\n",
       "              \n",
       "                       [[ 3.3932e-02, -1.5857e-02,  4.0290e-02],\n",
       "                        [-8.9148e-04, -1.1890e-02, -3.0553e-02],\n",
       "                        [ 1.3106e-02,  1.4446e-02, -2.8366e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0733e-02, -7.0526e-03,  2.6500e-02],\n",
       "                        [-1.8395e-02, -2.8225e-02,  1.9239e-02],\n",
       "                        [ 1.6200e-02, -2.1013e-02, -7.2787e-03]],\n",
       "              \n",
       "                       [[-4.5112e-03, -2.4284e-02, -2.3810e-02],\n",
       "                        [ 2.1409e-02, -1.4143e-02, -4.5077e-03],\n",
       "                        [-2.0808e-02, -2.5905e-02,  5.1972e-04]],\n",
       "              \n",
       "                       [[ 2.5453e-02,  1.0453e-03, -1.5197e-02],\n",
       "                        [ 2.8536e-02,  9.5682e-03, -1.4249e-02],\n",
       "                        [-2.1673e-02,  3.3517e-02,  2.5071e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6274e-02, -1.8274e-03,  2.2195e-02],\n",
       "                        [-3.9242e-02, -2.6047e-02,  3.2152e-02],\n",
       "                        [ 3.7798e-02,  2.6034e-03, -1.1605e-03]],\n",
       "              \n",
       "                       [[-3.6156e-02, -2.7064e-02, -8.6997e-03],\n",
       "                        [ 2.2546e-02, -3.3085e-02,  7.3288e-03],\n",
       "                        [ 1.7441e-02, -9.1410e-03, -1.4159e-02]],\n",
       "              \n",
       "                       [[-1.1977e-02, -1.6765e-02, -3.7746e-02],\n",
       "                        [ 3.2048e-02,  3.0754e-02,  8.0139e-03],\n",
       "                        [-2.0674e-02,  1.2050e-02,  1.3567e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0935e-02,  2.0450e-02,  2.4666e-02],\n",
       "                        [ 1.5512e-02, -3.2377e-02,  3.3219e-02],\n",
       "                        [ 3.8202e-02, -1.6083e-02,  9.6351e-03]],\n",
       "              \n",
       "                       [[ 6.5982e-03, -8.4959e-03,  5.1555e-04],\n",
       "                        [-2.2151e-02,  1.5857e-02, -2.7418e-02],\n",
       "                        [-1.1737e-03, -2.7482e-02, -2.9330e-02]],\n",
       "              \n",
       "                       [[-3.7841e-02,  1.2915e-02, -1.0636e-02],\n",
       "                        [ 2.7195e-02, -1.9293e-02, -2.9139e-03],\n",
       "                        [ 2.1054e-02,  6.8875e-03,  3.3250e-02]]]])),\n",
       "             ('model.features.conv_block4.cl.bias',\n",
       "              tensor([-0.0133, -0.0162, -0.0303,  0.0311,  0.0395, -0.0005, -0.0148, -0.0216,\n",
       "                       0.0089,  0.0162,  0.0355,  0.0288,  0.0384,  0.0373, -0.0172,  0.0153,\n",
       "                       0.0338, -0.0080, -0.0165,  0.0381, -0.0224,  0.0219,  0.0015, -0.0325,\n",
       "                      -0.0104,  0.0236,  0.0137,  0.0290, -0.0258,  0.0148,  0.0373,  0.0401,\n",
       "                       0.0057,  0.0044,  0.0220, -0.0290, -0.0142,  0.0128,  0.0008,  0.0144,\n",
       "                       0.0078,  0.0155,  0.0027,  0.0384, -0.0010, -0.0340,  0.0212,  0.0170,\n",
       "                       0.0251,  0.0324,  0.0351,  0.0172,  0.0341,  0.0165,  0.0121, -0.0213,\n",
       "                      -0.0208,  0.0145,  0.0223, -0.0110,  0.0218,  0.0278, -0.0055, -0.0168])),\n",
       "             ('model.features.conv_block4.bn.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('model.features.conv_block4.bn.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('model.features.conv_block4.bn.running_mean',\n",
       "              tensor([ 0.0012,  0.0922, -0.1172,  0.1533,  0.0105, -0.2257,  0.0892, -0.0395,\n",
       "                      -0.0883,  0.0107,  0.0111, -0.1956, -0.0716, -0.1515,  0.1039,  0.1725,\n",
       "                      -0.0439,  0.0030, -0.0038, -0.2941,  0.0917, -0.0447, -0.1137,  0.3024,\n",
       "                       0.2471,  0.1878, -0.2666,  0.0270,  0.1093,  0.0356,  0.1378, -0.0593,\n",
       "                      -0.1585,  0.1344,  0.1605, -0.0209, -0.0856,  0.1266, -0.0329, -0.0016,\n",
       "                       0.1552, -0.0798, -0.0353, -0.0454, -0.0566, -0.0870, -0.3680,  0.0732,\n",
       "                      -0.1738, -0.0109,  0.0115,  0.2553, -0.0344,  0.1322,  0.0180, -0.0657,\n",
       "                      -0.0531,  0.0032, -0.0525, -0.0233, -0.0430,  0.0452, -0.0290, -0.1549])),\n",
       "             ('model.features.conv_block4.bn.running_var',\n",
       "              tensor([0.8379, 0.8384, 0.8393, 0.8398, 0.8397, 0.8372, 0.8379, 0.8374, 0.8390,\n",
       "                      0.8354, 0.8347, 0.8385, 0.8379, 0.8394, 0.8411, 0.8375, 0.8362, 0.8397,\n",
       "                      0.8381, 0.8357, 0.8401, 0.8388, 0.8403, 0.8407, 0.8412, 0.8388, 0.8411,\n",
       "                      0.8390, 0.8409, 0.8383, 0.8423, 0.8357, 0.8366, 0.8388, 0.8367, 0.8396,\n",
       "                      0.8370, 0.8393, 0.8392, 0.8379, 0.8367, 0.8374, 0.8403, 0.8386, 0.8365,\n",
       "                      0.8353, 0.8357, 0.8391, 0.8368, 0.8401, 0.8374, 0.8378, 0.8399, 0.8398,\n",
       "                      0.8377, 0.8370, 0.8406, 0.8376, 0.8375, 0.8363, 0.8382, 0.8378, 0.8373,\n",
       "                      0.8365])),\n",
       "             ('model.features.conv_block4.bn.num_batches_tracked', tensor(2)),\n",
       "             ('model.out.weight',\n",
       "              tensor([[ 1.3976e-02, -2.2298e-02,  4.1014e-02,  ...,  2.9085e-02,\n",
       "                       -2.5434e-02,  3.1472e-02],\n",
       "                      [ 1.4059e-02, -8.5345e-04,  8.0341e-03,  ...,  3.6558e-02,\n",
       "                        3.3003e-02,  2.5197e-02],\n",
       "                      [-3.2516e-02, -2.7478e-05,  3.0782e-03,  ..., -7.3217e-03,\n",
       "                        3.2358e-02,  4.0398e-02],\n",
       "                      [ 2.5058e-02,  3.4104e-02,  6.7627e-03,  ..., -3.3432e-02,\n",
       "                        2.8104e-02, -2.5581e-02],\n",
       "                      [ 1.9341e-02,  1.6546e-02,  2.1527e-02,  ...,  3.0894e-02,\n",
       "                        7.3708e-03, -3.0072e-02]])),\n",
       "             ('model.out.bias', tensor([0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.features.conv_block1.cl.weight',\n",
       "              tensor([[[[-0.1623, -0.0017,  0.0474],\n",
       "                        [-0.0299, -0.1153, -0.1814],\n",
       "                        [ 0.0328,  0.0757, -0.1247]],\n",
       "              \n",
       "                       [[-0.0926,  0.0803,  0.0312],\n",
       "                        [-0.1704,  0.1027,  0.1454],\n",
       "                        [-0.0988,  0.0387,  0.0800]],\n",
       "              \n",
       "                       [[ 0.0039, -0.0360,  0.1487],\n",
       "                        [-0.0547,  0.1525,  0.1786],\n",
       "                        [-0.1867,  0.0908,  0.1110]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1720, -0.0133,  0.1300],\n",
       "                        [-0.1436, -0.1104, -0.0792],\n",
       "                        [-0.0509, -0.0066,  0.0674]],\n",
       "              \n",
       "                       [[ 0.0087,  0.0206,  0.0270],\n",
       "                        [-0.0970,  0.0400,  0.0800],\n",
       "                        [-0.1621,  0.1012,  0.1042]],\n",
       "              \n",
       "                       [[-0.1638,  0.0293,  0.0713],\n",
       "                        [ 0.1578,  0.1033,  0.0822],\n",
       "                        [-0.1699,  0.1017,  0.1795]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1901,  0.1152, -0.1482],\n",
       "                        [ 0.0663, -0.1590,  0.0401],\n",
       "                        [-0.0292, -0.1539, -0.1601]],\n",
       "              \n",
       "                       [[ 0.0139,  0.1563, -0.0862],\n",
       "                        [-0.1825, -0.1088,  0.0695],\n",
       "                        [-0.0366, -0.1760, -0.0197]],\n",
       "              \n",
       "                       [[-0.0721,  0.1476, -0.0823],\n",
       "                        [-0.0906,  0.0757, -0.1253],\n",
       "                        [-0.0314, -0.0129,  0.1761]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0092, -0.0724,  0.0079],\n",
       "                        [-0.1846,  0.0609, -0.0990],\n",
       "                        [-0.1812, -0.0003,  0.1095]],\n",
       "              \n",
       "                       [[ 0.0556,  0.1034,  0.0860],\n",
       "                        [-0.0683,  0.1477,  0.0785],\n",
       "                        [ 0.0538, -0.0146,  0.0169]],\n",
       "              \n",
       "                       [[ 0.1140,  0.1537,  0.1509],\n",
       "                        [ 0.0543, -0.1496,  0.0589],\n",
       "                        [ 0.1173,  0.0619, -0.1451]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1052, -0.0620, -0.0413],\n",
       "                        [-0.0037,  0.1811, -0.0876],\n",
       "                        [-0.0294, -0.1718, -0.0296]],\n",
       "              \n",
       "                       [[ 0.0218,  0.1147,  0.0902],\n",
       "                        [-0.0124, -0.1755, -0.1344],\n",
       "                        [-0.0112, -0.1311,  0.0306]],\n",
       "              \n",
       "                       [[-0.1071,  0.0281, -0.0552],\n",
       "                        [ 0.1287, -0.1738,  0.1219],\n",
       "                        [-0.0433, -0.1061,  0.0264]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1003,  0.1618,  0.0124],\n",
       "                        [-0.0923, -0.0875, -0.1918],\n",
       "                        [ 0.1647,  0.1815, -0.0043]],\n",
       "              \n",
       "                       [[ 0.0018,  0.1885, -0.0765],\n",
       "                        [-0.0617,  0.0443, -0.1316],\n",
       "                        [-0.1389,  0.0111,  0.1312]],\n",
       "              \n",
       "                       [[ 0.0216,  0.0490, -0.1049],\n",
       "                        [-0.1563,  0.1193,  0.1874],\n",
       "                        [-0.0201, -0.0811, -0.1108]]]])),\n",
       "             ('model.features.conv_block1.cl.bias',\n",
       "              tensor([-0.1394,  0.0061, -0.1372, -0.1611, -0.1246,  0.0576,  0.1232, -0.1770,\n",
       "                       0.0010,  0.0921,  0.0504,  0.0260, -0.1894, -0.1154,  0.1402, -0.1499,\n",
       "                      -0.0906,  0.0410,  0.0408, -0.1846,  0.0479, -0.0007, -0.1798, -0.0698,\n",
       "                      -0.1299,  0.0537, -0.0612,  0.0558, -0.0935,  0.1530,  0.1436,  0.1439,\n",
       "                       0.0437, -0.1780, -0.1611,  0.0609, -0.0946, -0.1132,  0.0526,  0.1230,\n",
       "                       0.1698, -0.1279, -0.0513,  0.0751, -0.0552, -0.1782,  0.0083,  0.0035,\n",
       "                       0.0197, -0.0966,  0.0559,  0.1427, -0.1002, -0.1715, -0.1534,  0.0060,\n",
       "                       0.1832, -0.1724,  0.1263, -0.1617,  0.1727, -0.0617, -0.1205, -0.0349])),\n",
       "             ('model.features.conv_block1.bn.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('model.features.conv_block1.bn.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('model.features.conv_block1.bn.running_mean',\n",
       "              tensor([-0.0265,  0.0013, -0.0263, -0.0306, -0.0237,  0.0110,  0.0238, -0.0341,\n",
       "                       0.0001,  0.0180,  0.0099,  0.0052, -0.0359, -0.0221,  0.0266, -0.0284,\n",
       "                      -0.0173,  0.0077,  0.0074, -0.0346,  0.0086, -0.0003, -0.0342, -0.0132,\n",
       "                      -0.0243,  0.0102, -0.0114,  0.0101, -0.0180,  0.0292,  0.0274,  0.0275,\n",
       "                       0.0086, -0.0340, -0.0309,  0.0114, -0.0177, -0.0215,  0.0100,  0.0234,\n",
       "                       0.0328, -0.0242, -0.0098,  0.0144, -0.0107, -0.0341,  0.0019,  0.0008,\n",
       "                       0.0038, -0.0186,  0.0108,  0.0272, -0.0194, -0.0327, -0.0292,  0.0011,\n",
       "                       0.0346, -0.0326,  0.0237, -0.0306,  0.0327, -0.0115, -0.0232, -0.0067])),\n",
       "             ('model.features.conv_block1.bn.running_var',\n",
       "              tensor([0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                      0.8100])),\n",
       "             ('model.features.conv_block1.bn.num_batches_tracked', tensor(2)),\n",
       "             ('model.features.conv_block2.cl.weight',\n",
       "              tensor([[[[-3.7927e-02,  1.8433e-02,  1.1347e-02],\n",
       "                        [ 3.7656e-02,  8.7175e-03,  3.1939e-02],\n",
       "                        [-2.1264e-02,  2.5047e-02,  1.4723e-03]],\n",
       "              \n",
       "                       [[ 1.6700e-02, -3.6713e-03, -3.6093e-02],\n",
       "                        [ 2.6540e-02, -3.2410e-02, -2.7422e-03],\n",
       "                        [-4.8145e-03, -1.1295e-03,  3.8680e-02]],\n",
       "              \n",
       "                       [[-1.3997e-02,  3.4379e-02, -1.9653e-02],\n",
       "                        [ 3.5368e-02,  2.9425e-02,  5.5878e-04],\n",
       "                        [-1.1563e-02,  2.9978e-02, -1.6815e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.1353e-02, -7.7124e-03,  3.6018e-02],\n",
       "                        [-2.7176e-02, -5.1315e-03,  2.8327e-02],\n",
       "                        [-2.4774e-02,  7.4069e-03, -1.3264e-02]],\n",
       "              \n",
       "                       [[-2.7867e-02,  2.2814e-02, -3.2717e-02],\n",
       "                        [-1.0275e-02,  1.9114e-02, -3.2051e-02],\n",
       "                        [-6.8959e-03,  3.3153e-02,  2.8298e-03]],\n",
       "              \n",
       "                       [[-5.3128e-03,  1.4971e-02, -2.6541e-02],\n",
       "                        [-3.8398e-03, -1.4895e-02, -1.1782e-02],\n",
       "                        [ 4.1084e-02, -1.4202e-02,  2.3835e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7566e-02, -2.2950e-02, -1.2309e-02],\n",
       "                        [-1.8173e-04, -1.7255e-02, -5.2971e-03],\n",
       "                        [-3.7603e-02,  2.3253e-02, -8.5642e-03]],\n",
       "              \n",
       "                       [[-2.4765e-02,  2.5187e-02, -3.2083e-02],\n",
       "                        [ 9.9596e-04, -2.9622e-02,  6.6066e-04],\n",
       "                        [-1.9235e-02,  3.0808e-02, -2.1943e-02]],\n",
       "              \n",
       "                       [[ 2.3963e-02, -1.4421e-02, -2.8244e-02],\n",
       "                        [-3.7864e-02,  2.0384e-02,  4.1255e-03],\n",
       "                        [-1.9360e-03,  2.8627e-02,  7.0025e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3974e-02, -3.6804e-02, -2.0411e-02],\n",
       "                        [ 1.9338e-03,  1.6671e-02, -2.2251e-02],\n",
       "                        [-3.2498e-02, -2.3095e-02, -1.7086e-02]],\n",
       "              \n",
       "                       [[-2.9996e-02,  4.0958e-02, -1.4566e-02],\n",
       "                        [-1.8665e-02, -2.4553e-02,  8.4303e-03],\n",
       "                        [ 4.1165e-02,  2.1262e-02,  3.7133e-02]],\n",
       "              \n",
       "                       [[ 8.2771e-03,  1.4452e-02,  2.2118e-03],\n",
       "                        [ 1.1195e-02, -4.9368e-03, -2.0375e-02],\n",
       "                        [ 5.6846e-03, -7.7862e-04, -2.7212e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9135e-02,  2.0752e-02,  7.9436e-03],\n",
       "                        [ 2.7502e-02, -5.1691e-03, -3.3038e-02],\n",
       "                        [ 5.3699e-03,  3.4598e-02, -2.6794e-02]],\n",
       "              \n",
       "                       [[ 3.0548e-02, -2.8727e-02, -2.4892e-02],\n",
       "                        [-3.8073e-02,  3.5895e-02, -1.6745e-02],\n",
       "                        [-5.6889e-05, -1.8122e-02,  3.3457e-02]],\n",
       "              \n",
       "                       [[ 1.1520e-02,  6.1168e-03, -1.5497e-02],\n",
       "                        [-3.3231e-03, -2.2384e-02,  4.4887e-03],\n",
       "                        [ 2.4497e-02, -3.6577e-02,  3.8162e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9383e-02,  3.5572e-02,  3.0361e-02],\n",
       "                        [ 5.2571e-03, -1.9084e-02, -4.1557e-02],\n",
       "                        [ 3.5408e-02,  3.7693e-02,  4.2172e-03]],\n",
       "              \n",
       "                       [[-5.9076e-04, -2.4707e-02,  3.8281e-02],\n",
       "                        [ 3.7915e-02, -3.9129e-02, -1.5071e-02],\n",
       "                        [ 2.6763e-02, -3.6381e-03, -8.2037e-03]],\n",
       "              \n",
       "                       [[-1.3659e-02,  9.3709e-03, -1.1886e-02],\n",
       "                        [ 9.4851e-03,  2.6101e-03, -6.9711e-03],\n",
       "                        [ 1.1749e-02, -1.1099e-02, -3.7763e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8995e-02, -1.4276e-02, -1.3638e-02],\n",
       "                        [ 1.8611e-02,  4.1182e-02,  2.4740e-02],\n",
       "                        [-3.1450e-02,  9.1232e-03, -3.0759e-02]],\n",
       "              \n",
       "                       [[ 3.3693e-02, -2.4498e-02,  3.5756e-02],\n",
       "                        [ 2.7887e-02, -2.7266e-02,  5.1399e-03],\n",
       "                        [ 7.2076e-04,  2.9705e-02, -1.2516e-03]],\n",
       "              \n",
       "                       [[-2.4065e-02,  4.0313e-02,  1.1797e-02],\n",
       "                        [ 1.1720e-02,  1.0017e-02, -2.0945e-02],\n",
       "                        [-2.1405e-02,  1.8600e-02,  1.9361e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.1294e-03,  1.9879e-02, -3.8999e-02],\n",
       "                        [-1.1913e-02, -3.8740e-02,  6.2888e-03],\n",
       "                        [-4.2951e-03,  2.0605e-02,  1.2058e-02]],\n",
       "              \n",
       "                       [[-3.3599e-02, -3.1169e-02, -3.1307e-02],\n",
       "                        [ 3.5673e-02, -3.2389e-02,  1.7420e-02],\n",
       "                        [ 2.0430e-02, -3.2101e-03,  2.4777e-03]],\n",
       "              \n",
       "                       [[ 4.4024e-03, -1.9553e-02,  3.9463e-02],\n",
       "                        [-2.4723e-02, -1.6534e-02,  2.6077e-02],\n",
       "                        [-1.7426e-02, -3.8240e-02, -1.4701e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9894e-02, -3.5411e-02, -3.1081e-02],\n",
       "                        [ 1.3125e-03, -2.2144e-02,  1.9719e-02],\n",
       "                        [ 8.9777e-03, -2.1864e-03,  4.4644e-03]],\n",
       "              \n",
       "                       [[-3.6740e-02,  3.3483e-02,  5.8988e-03],\n",
       "                        [ 3.3530e-03,  2.3579e-02, -2.4786e-02],\n",
       "                        [ 2.8825e-02, -2.6302e-02,  1.1399e-02]],\n",
       "              \n",
       "                       [[ 3.2536e-02, -8.7696e-03,  1.8184e-02],\n",
       "                        [-3.0402e-02, -8.4886e-03, -2.1232e-02],\n",
       "                        [ 8.0884e-03, -1.3887e-03, -1.4119e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0763e-02,  2.0201e-02,  1.4244e-02],\n",
       "                        [-5.8302e-03, -2.4964e-02, -4.2201e-03],\n",
       "                        [-1.2697e-02,  1.1849e-02, -1.6668e-02]],\n",
       "              \n",
       "                       [[ 1.7800e-02,  2.9264e-02, -2.7779e-02],\n",
       "                        [-2.7842e-02,  2.1841e-02,  7.7532e-03],\n",
       "                        [-7.7170e-03,  3.2372e-02,  1.3879e-02]],\n",
       "              \n",
       "                       [[ 4.6317e-03, -2.7629e-02,  2.3330e-02],\n",
       "                        [ 3.9785e-03, -4.0161e-02, -2.8167e-02],\n",
       "                        [ 2.8499e-02,  4.0928e-03, -3.8191e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3917e-02, -5.1038e-03,  1.0760e-02],\n",
       "                        [-3.0983e-02,  3.4290e-02, -8.4794e-03],\n",
       "                        [ 3.5742e-02, -1.7496e-02,  2.9554e-02]],\n",
       "              \n",
       "                       [[-1.5779e-02,  1.2107e-02, -1.2561e-03],\n",
       "                        [ 3.7729e-02, -1.3588e-02,  2.6842e-02],\n",
       "                        [ 1.2282e-02,  5.9187e-03,  3.2053e-02]],\n",
       "              \n",
       "                       [[ 2.0683e-02,  1.2413e-02, -3.4295e-02],\n",
       "                        [-2.4512e-02,  3.0522e-02, -4.8837e-03],\n",
       "                        [-3.5213e-02, -1.0895e-02, -1.1347e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.9722e-03, -2.6971e-02, -5.2001e-03],\n",
       "                        [-2.1804e-02, -2.1454e-02,  2.4280e-02],\n",
       "                        [-1.6157e-02, -1.8030e-02, -2.0757e-02]],\n",
       "              \n",
       "                       [[-3.9223e-03,  2.3701e-02, -2.3210e-03],\n",
       "                        [ 1.2497e-02,  3.4894e-03,  3.6398e-02],\n",
       "                        [ 3.9213e-02,  8.6516e-03, -1.6630e-02]],\n",
       "              \n",
       "                       [[-2.7015e-03,  1.1478e-02,  3.5990e-03],\n",
       "                        [ 1.2411e-02, -3.0050e-02, -3.1527e-02],\n",
       "                        [ 4.1424e-02,  4.8585e-03,  3.3720e-02]]]])),\n",
       "             ('model.features.conv_block2.cl.bias',\n",
       "              tensor([ 0.0395,  0.0322,  0.0162, -0.0055,  0.0401, -0.0067,  0.0162, -0.0248,\n",
       "                      -0.0313, -0.0104,  0.0180,  0.0259, -0.0290, -0.0379,  0.0409, -0.0413,\n",
       "                       0.0212,  0.0222,  0.0068,  0.0259, -0.0095,  0.0059,  0.0233,  0.0194,\n",
       "                       0.0225,  0.0221,  0.0076,  0.0186,  0.0414,  0.0103, -0.0299,  0.0044,\n",
       "                       0.0206,  0.0130,  0.0341, -0.0260, -0.0351,  0.0197,  0.0060,  0.0080,\n",
       "                       0.0031, -0.0263, -0.0379, -0.0200,  0.0346, -0.0228, -0.0393,  0.0069,\n",
       "                      -0.0379, -0.0369,  0.0269, -0.0277,  0.0042, -0.0231,  0.0307,  0.0096,\n",
       "                      -0.0212, -0.0007, -0.0002,  0.0332,  0.0013,  0.0292, -0.0392, -0.0045])),\n",
       "             ('model.features.conv_block2.bn.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('model.features.conv_block2.bn.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('model.features.conv_block2.bn.running_mean',\n",
       "              tensor([-0.0021,  0.0094,  0.0385, -0.0359,  0.0144,  0.0270,  0.0330,  0.0333,\n",
       "                       0.0143, -0.0013, -0.0122, -0.0016, -0.0063,  0.0036, -0.0169,  0.0104,\n",
       "                       0.0050, -0.0166,  0.0004, -0.0071, -0.0263,  0.0117,  0.0181, -0.0135,\n",
       "                       0.0349,  0.0202,  0.0007, -0.0133,  0.0122, -0.0299, -0.0439, -0.0481,\n",
       "                      -0.0273,  0.0106,  0.0396, -0.0233,  0.0124,  0.0267, -0.0064, -0.0118,\n",
       "                       0.0056, -0.0185, -0.0078, -0.0217, -0.0377,  0.0181,  0.0375, -0.0269,\n",
       "                       0.0141,  0.0215,  0.0199, -0.0090,  0.0263,  0.0379, -0.0103, -0.0199,\n",
       "                      -0.0241, -0.0033,  0.0412, -0.0304,  0.0062, -0.0213, -0.0357, -0.0234])),\n",
       "             ('model.features.conv_block2.bn.running_var',\n",
       "              tensor([0.8115, 0.8111, 0.8113, 0.8109, 0.8111, 0.8112, 0.8112, 0.8110, 0.8112,\n",
       "                      0.8114, 0.8110, 0.8114, 0.8112, 0.8112, 0.8112, 0.8114, 0.8112, 0.8111,\n",
       "                      0.8114, 0.8114, 0.8111, 0.8113, 0.8111, 0.8110, 0.8113, 0.8112, 0.8115,\n",
       "                      0.8110, 0.8113, 0.8112, 0.8112, 0.8112, 0.8111, 0.8112, 0.8111, 0.8110,\n",
       "                      0.8112, 0.8112, 0.8111, 0.8114, 0.8112, 0.8112, 0.8112, 0.8109, 0.8114,\n",
       "                      0.8111, 0.8109, 0.8111, 0.8111, 0.8112, 0.8111, 0.8112, 0.8113, 0.8111,\n",
       "                      0.8111, 0.8110, 0.8111, 0.8111, 0.8116, 0.8112, 0.8113, 0.8113, 0.8112,\n",
       "                      0.8114])),\n",
       "             ('model.features.conv_block2.bn.num_batches_tracked', tensor(2)),\n",
       "             ('model.features.conv_block3.cl.weight',\n",
       "              tensor([[[[ 0.0304, -0.0145, -0.0325],\n",
       "                        [ 0.0244,  0.0073, -0.0224],\n",
       "                        [ 0.0313,  0.0057,  0.0399]],\n",
       "              \n",
       "                       [[-0.0392, -0.0266, -0.0004],\n",
       "                        [-0.0192,  0.0338,  0.0349],\n",
       "                        [-0.0237, -0.0379,  0.0041]],\n",
       "              \n",
       "                       [[-0.0409,  0.0042, -0.0230],\n",
       "                        [ 0.0220, -0.0244,  0.0045],\n",
       "                        [-0.0177,  0.0291,  0.0360]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0306,  0.0240, -0.0289],\n",
       "                        [ 0.0083,  0.0312, -0.0381],\n",
       "                        [-0.0399, -0.0186,  0.0345]],\n",
       "              \n",
       "                       [[ 0.0182, -0.0284,  0.0385],\n",
       "                        [-0.0300,  0.0301, -0.0060],\n",
       "                        [ 0.0151,  0.0153,  0.0164]],\n",
       "              \n",
       "                       [[-0.0325,  0.0140, -0.0393],\n",
       "                        [-0.0136, -0.0376,  0.0019],\n",
       "                        [-0.0334, -0.0369,  0.0208]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0015, -0.0092,  0.0262],\n",
       "                        [-0.0352, -0.0024,  0.0413],\n",
       "                        [ 0.0315,  0.0250, -0.0097]],\n",
       "              \n",
       "                       [[-0.0033,  0.0284, -0.0276],\n",
       "                        [ 0.0132,  0.0414,  0.0252],\n",
       "                        [-0.0316,  0.0345,  0.0348]],\n",
       "              \n",
       "                       [[ 0.0204, -0.0310,  0.0115],\n",
       "                        [ 0.0035,  0.0019, -0.0379],\n",
       "                        [-0.0141, -0.0416,  0.0146]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0027, -0.0107, -0.0032],\n",
       "                        [ 0.0057,  0.0359,  0.0017],\n",
       "                        [-0.0082,  0.0189, -0.0382]],\n",
       "              \n",
       "                       [[ 0.0235,  0.0158,  0.0225],\n",
       "                        [ 0.0004, -0.0199, -0.0276],\n",
       "                        [ 0.0099,  0.0314, -0.0319]],\n",
       "              \n",
       "                       [[-0.0241,  0.0369,  0.0399],\n",
       "                        [-0.0359, -0.0154, -0.0024],\n",
       "                        [ 0.0163,  0.0003,  0.0003]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0128,  0.0366, -0.0108],\n",
       "                        [ 0.0198, -0.0075, -0.0363],\n",
       "                        [ 0.0225, -0.0124, -0.0225]],\n",
       "              \n",
       "                       [[ 0.0245,  0.0066,  0.0044],\n",
       "                        [ 0.0160,  0.0157, -0.0284],\n",
       "                        [-0.0317, -0.0387, -0.0413]],\n",
       "              \n",
       "                       [[-0.0273, -0.0142,  0.0284],\n",
       "                        [-0.0223,  0.0100,  0.0234],\n",
       "                        [-0.0203,  0.0059,  0.0365]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0249,  0.0313, -0.0062],\n",
       "                        [-0.0046,  0.0152, -0.0032],\n",
       "                        [ 0.0394,  0.0177,  0.0183]],\n",
       "              \n",
       "                       [[ 0.0105,  0.0098,  0.0143],\n",
       "                        [ 0.0043, -0.0370, -0.0245],\n",
       "                        [ 0.0200,  0.0116, -0.0123]],\n",
       "              \n",
       "                       [[-0.0294, -0.0205,  0.0139],\n",
       "                        [-0.0332,  0.0335,  0.0333],\n",
       "                        [ 0.0053, -0.0104, -0.0252]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0066,  0.0156,  0.0372],\n",
       "                        [-0.0281,  0.0262, -0.0352],\n",
       "                        [-0.0007, -0.0129,  0.0056]],\n",
       "              \n",
       "                       [[ 0.0378,  0.0112, -0.0185],\n",
       "                        [-0.0012,  0.0156, -0.0014],\n",
       "                        [ 0.0235, -0.0292, -0.0091]],\n",
       "              \n",
       "                       [[-0.0033, -0.0309, -0.0138],\n",
       "                        [-0.0240,  0.0381, -0.0046],\n",
       "                        [ 0.0063, -0.0334, -0.0354]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0150,  0.0181,  0.0366],\n",
       "                        [-0.0070, -0.0312, -0.0205],\n",
       "                        [ 0.0272,  0.0373, -0.0042]],\n",
       "              \n",
       "                       [[ 0.0313,  0.0047, -0.0397],\n",
       "                        [-0.0053, -0.0131,  0.0337],\n",
       "                        [ 0.0108,  0.0076,  0.0024]],\n",
       "              \n",
       "                       [[ 0.0104, -0.0116, -0.0081],\n",
       "                        [-0.0002, -0.0412,  0.0141],\n",
       "                        [-0.0065,  0.0300,  0.0008]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0041,  0.0221, -0.0207],\n",
       "                        [ 0.0218,  0.0333, -0.0060],\n",
       "                        [ 0.0332, -0.0013, -0.0252]],\n",
       "              \n",
       "                       [[-0.0303, -0.0109,  0.0179],\n",
       "                        [ 0.0358,  0.0096,  0.0361],\n",
       "                        [-0.0188,  0.0103, -0.0245]],\n",
       "              \n",
       "                       [[-0.0245,  0.0019, -0.0384],\n",
       "                        [-0.0335, -0.0062,  0.0144],\n",
       "                        [ 0.0004, -0.0323,  0.0244]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0327,  0.0112, -0.0119],\n",
       "                        [-0.0269, -0.0060, -0.0293],\n",
       "                        [ 0.0232, -0.0149,  0.0124]],\n",
       "              \n",
       "                       [[-0.0100, -0.0380, -0.0237],\n",
       "                        [-0.0186,  0.0005,  0.0301],\n",
       "                        [ 0.0281, -0.0042,  0.0278]],\n",
       "              \n",
       "                       [[-0.0404,  0.0232,  0.0043],\n",
       "                        [-0.0076, -0.0326,  0.0386],\n",
       "                        [-0.0328, -0.0357,  0.0154]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0296,  0.0289, -0.0341],\n",
       "                        [-0.0167,  0.0019,  0.0192],\n",
       "                        [-0.0218, -0.0248,  0.0270]],\n",
       "              \n",
       "                       [[-0.0114,  0.0255,  0.0002],\n",
       "                        [ 0.0382, -0.0054, -0.0175],\n",
       "                        [ 0.0227,  0.0340,  0.0381]],\n",
       "              \n",
       "                       [[ 0.0073,  0.0408, -0.0042],\n",
       "                        [ 0.0175, -0.0170, -0.0043],\n",
       "                        [ 0.0087, -0.0342,  0.0092]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0263, -0.0133, -0.0225],\n",
       "                        [-0.0306,  0.0173,  0.0092],\n",
       "                        [ 0.0224,  0.0064,  0.0008]],\n",
       "              \n",
       "                       [[-0.0059,  0.0319,  0.0206],\n",
       "                        [-0.0349,  0.0269,  0.0245],\n",
       "                        [ 0.0415,  0.0141, -0.0411]],\n",
       "              \n",
       "                       [[-0.0092,  0.0401, -0.0048],\n",
       "                        [ 0.0116, -0.0073, -0.0327],\n",
       "                        [-0.0363,  0.0083,  0.0104]]]])),\n",
       "             ('model.features.conv_block3.cl.bias',\n",
       "              tensor([-0.0166, -0.0381, -0.0043, -0.0337, -0.0384, -0.0106, -0.0061,  0.0321,\n",
       "                      -0.0347, -0.0036, -0.0022,  0.0366,  0.0334, -0.0249, -0.0390, -0.0076,\n",
       "                      -0.0369,  0.0146,  0.0049,  0.0354, -0.0096, -0.0157, -0.0048, -0.0235,\n",
       "                      -0.0084,  0.0322,  0.0229,  0.0107, -0.0292,  0.0265, -0.0296, -0.0321,\n",
       "                      -0.0290,  0.0283,  0.0347, -0.0280,  0.0416,  0.0345,  0.0205, -0.0240,\n",
       "                      -0.0021, -0.0402, -0.0101,  0.0253,  0.0413, -0.0383,  0.0086, -0.0188,\n",
       "                       0.0262,  0.0221,  0.0049, -0.0210,  0.0091,  0.0337, -0.0033,  0.0203,\n",
       "                      -0.0062, -0.0099,  0.0349, -0.0410,  0.0200, -0.0195, -0.0003, -0.0333])),\n",
       "             ('model.features.conv_block3.bn.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('model.features.conv_block3.bn.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('model.features.conv_block3.bn.running_mean',\n",
       "              tensor([-0.0174,  0.0611, -0.0577,  0.0472, -0.2896,  0.1669, -0.1291, -0.1750,\n",
       "                       0.0447, -0.1903,  0.1447,  0.0180,  0.1067,  0.0847,  0.0491, -0.0032,\n",
       "                       0.0042,  0.1980,  0.0532, -0.0444,  0.2035,  0.0686, -0.0896,  0.1867,\n",
       "                       0.0896, -0.1201,  0.2195,  0.0201, -0.0375, -0.0218,  0.0923,  0.2247,\n",
       "                       0.0849, -0.0648, -0.1735,  0.0112,  0.0023,  0.0930,  0.1376, -0.2941,\n",
       "                       0.1051, -0.1022,  0.0859, -0.0852,  0.0136,  0.1057,  0.0477,  0.0911,\n",
       "                       0.1628,  0.0347, -0.1101, -0.0879,  0.0058, -0.2478, -0.0663,  0.0889,\n",
       "                       0.1393,  0.0789, -0.0208,  0.0055,  0.1028, -0.0324,  0.0424, -0.0301])),\n",
       "             ('model.features.conv_block3.bn.running_var',\n",
       "              tensor([0.8382, 0.8361, 0.8378, 0.8368, 0.8366, 0.8368, 0.8382, 0.8396, 0.8376,\n",
       "                      0.8392, 0.8371, 0.8400, 0.8374, 0.8370, 0.8398, 0.8392, 0.8382, 0.8384,\n",
       "                      0.8382, 0.8353, 0.8425, 0.8362, 0.8365, 0.8387, 0.8385, 0.8376, 0.8388,\n",
       "                      0.8411, 0.8377, 0.8393, 0.8409, 0.8379, 0.8369, 0.8367, 0.8360, 0.8372,\n",
       "                      0.8388, 0.8409, 0.8369, 0.8377, 0.8395, 0.8391, 0.8413, 0.8376, 0.8367,\n",
       "                      0.8361, 0.8389, 0.8379, 0.8385, 0.8357, 0.8391, 0.8394, 0.8373, 0.8353,\n",
       "                      0.8389, 0.8377, 0.8414, 0.8401, 0.8374, 0.8382, 0.8414, 0.8391, 0.8358,\n",
       "                      0.8388])),\n",
       "             ('model.features.conv_block3.bn.num_batches_tracked', tensor(2)),\n",
       "             ('model.features.conv_block4.cl.weight',\n",
       "              tensor([[[[-1.9982e-02, -3.9725e-02, -3.8899e-02],\n",
       "                        [ 6.1684e-03, -3.6883e-02,  3.6105e-02],\n",
       "                        [-3.1963e-02, -2.0332e-02, -1.4034e-02]],\n",
       "              \n",
       "                       [[ 7.8589e-03,  4.1429e-02, -3.9654e-02],\n",
       "                        [ 2.4156e-02,  3.1202e-03, -3.9159e-03],\n",
       "                        [-3.2538e-02,  2.8815e-02, -3.2439e-02]],\n",
       "              \n",
       "                       [[-1.5833e-02, -9.4279e-03,  1.3458e-02],\n",
       "                        [ 1.8243e-02,  3.1937e-02, -3.2560e-02],\n",
       "                        [-2.2811e-02, -3.8484e-02,  2.7220e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4353e-02,  2.4609e-02, -8.1571e-03],\n",
       "                        [-2.0917e-02, -1.1538e-02,  3.1185e-02],\n",
       "                        [ 2.2156e-02,  3.5467e-02, -3.6269e-02]],\n",
       "              \n",
       "                       [[-2.0933e-02, -4.0497e-02,  3.0117e-02],\n",
       "                        [ 1.0031e-03, -1.6316e-02,  3.1823e-02],\n",
       "                        [ 6.8562e-03, -4.3866e-03, -3.5344e-02]],\n",
       "              \n",
       "                       [[ 4.0622e-02,  1.4547e-02, -4.9219e-05],\n",
       "                        [-7.5529e-03,  1.5969e-02,  1.8871e-02],\n",
       "                        [ 1.9470e-02, -3.4392e-02, -3.8485e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0744e-02,  1.5700e-02,  5.9227e-03],\n",
       "                        [ 3.6773e-02,  5.2455e-03,  4.1642e-02],\n",
       "                        [-3.7767e-02,  1.5742e-02,  3.2338e-02]],\n",
       "              \n",
       "                       [[ 3.3084e-02,  2.1187e-02,  4.1782e-03],\n",
       "                        [ 2.6501e-02,  3.4408e-02,  2.0683e-02],\n",
       "                        [-1.4361e-03,  3.9599e-02,  1.4607e-02]],\n",
       "              \n",
       "                       [[-4.3121e-03, -2.6927e-02,  1.4999e-02],\n",
       "                        [ 8.8503e-03, -1.5875e-02,  3.7465e-02],\n",
       "                        [ 2.3113e-02,  6.1879e-03,  1.8465e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7483e-02, -3.3464e-02, -2.1006e-02],\n",
       "                        [-2.6896e-02, -4.2867e-03, -2.1057e-02],\n",
       "                        [ 1.3569e-02, -9.3375e-03, -3.2317e-02]],\n",
       "              \n",
       "                       [[-2.9574e-02,  2.2819e-02,  4.6971e-03],\n",
       "                        [ 3.2549e-02, -2.4813e-02, -1.6776e-02],\n",
       "                        [ 5.1805e-04,  2.2879e-02, -1.1719e-02]],\n",
       "              \n",
       "                       [[-1.8016e-02,  3.1807e-02, -3.1352e-02],\n",
       "                        [-9.7339e-03,  3.2209e-02,  4.1002e-02],\n",
       "                        [-1.1149e-03, -3.0150e-02,  2.0974e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0608e-03, -3.1381e-03, -3.9339e-02],\n",
       "                        [ 2.7538e-02,  1.9081e-02,  3.3121e-02],\n",
       "                        [ 3.2777e-02, -2.6065e-02,  1.5223e-02]],\n",
       "              \n",
       "                       [[-2.5271e-02,  3.1774e-02,  2.3798e-02],\n",
       "                        [ 2.4479e-02, -1.1341e-02, -3.7881e-02],\n",
       "                        [-7.6354e-04,  3.6014e-02, -3.3636e-02]],\n",
       "              \n",
       "                       [[-3.8460e-02, -2.7443e-02,  1.7793e-02],\n",
       "                        [-1.4754e-02, -3.9596e-02, -1.0433e-03],\n",
       "                        [ 1.5699e-02,  2.7005e-02,  3.5851e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.7199e-02, -2.5396e-02, -3.2714e-02],\n",
       "                        [-1.7450e-02, -2.1622e-02,  2.3224e-02],\n",
       "                        [-4.9174e-03,  3.5183e-02, -1.6677e-02]],\n",
       "              \n",
       "                       [[ 1.3491e-02,  9.3542e-03, -3.2725e-02],\n",
       "                        [-1.9064e-02, -1.8689e-02,  3.4529e-02],\n",
       "                        [ 3.1561e-02,  7.8281e-04,  5.7665e-03]],\n",
       "              \n",
       "                       [[-2.4455e-02,  3.4877e-02,  1.3577e-02],\n",
       "                        [-5.6439e-03, -1.4751e-02, -3.8664e-02],\n",
       "                        [ 1.2691e-02,  2.0994e-02,  3.4089e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.3329e-02, -2.6177e-02,  4.0044e-02],\n",
       "                        [ 3.8585e-02, -3.9881e-02,  9.7852e-03],\n",
       "                        [ 2.2469e-02,  1.5998e-02,  3.8853e-02]],\n",
       "              \n",
       "                       [[ 2.1206e-02, -3.9349e-02, -1.0661e-02],\n",
       "                        [-1.8955e-02, -1.9475e-02, -1.8314e-02],\n",
       "                        [-2.0622e-02, -8.2282e-03,  2.7381e-02]],\n",
       "              \n",
       "                       [[-9.1181e-03,  2.0744e-02, -3.6061e-02],\n",
       "                        [-2.2899e-02,  2.3835e-02,  3.7955e-02],\n",
       "                        [ 3.9456e-02,  3.7118e-02,  1.6972e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.1606e-02, -3.8496e-02, -2.8824e-02],\n",
       "                        [-1.1160e-02, -3.7479e-03,  1.3896e-03],\n",
       "                        [ 2.1123e-02,  6.0680e-03, -9.8039e-03]],\n",
       "              \n",
       "                       [[-2.6278e-02,  3.8440e-02, -3.6441e-02],\n",
       "                        [-4.1065e-02,  1.9810e-02,  4.1384e-02],\n",
       "                        [ 2.6948e-02, -3.7542e-02, -2.5129e-02]],\n",
       "              \n",
       "                       [[-1.0679e-03, -3.9704e-02, -4.0348e-02],\n",
       "                        [ 2.3643e-02, -6.1728e-04, -9.8462e-03],\n",
       "                        [ 2.1131e-02,  2.5168e-02, -3.0080e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3186e-02, -2.9568e-02, -3.6842e-02],\n",
       "                        [-3.2133e-02,  2.9043e-02, -3.5908e-02],\n",
       "                        [ 4.1152e-02,  1.9320e-02, -4.2343e-03]],\n",
       "              \n",
       "                       [[-2.1554e-02, -6.8490e-03, -2.0831e-02],\n",
       "                        [ 3.6792e-02, -5.2844e-03,  2.9959e-02],\n",
       "                        [ 5.1584e-03, -3.7014e-02, -8.5069e-03]],\n",
       "              \n",
       "                       [[ 3.3932e-02, -1.5857e-02,  4.0290e-02],\n",
       "                        [-8.9148e-04, -1.1890e-02, -3.0553e-02],\n",
       "                        [ 1.3106e-02,  1.4446e-02, -2.8366e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0733e-02, -7.0526e-03,  2.6500e-02],\n",
       "                        [-1.8395e-02, -2.8225e-02,  1.9239e-02],\n",
       "                        [ 1.6200e-02, -2.1013e-02, -7.2787e-03]],\n",
       "              \n",
       "                       [[-4.5112e-03, -2.4284e-02, -2.3810e-02],\n",
       "                        [ 2.1409e-02, -1.4143e-02, -4.5077e-03],\n",
       "                        [-2.0808e-02, -2.5905e-02,  5.1972e-04]],\n",
       "              \n",
       "                       [[ 2.5453e-02,  1.0453e-03, -1.5197e-02],\n",
       "                        [ 2.8536e-02,  9.5682e-03, -1.4249e-02],\n",
       "                        [-2.1673e-02,  3.3517e-02,  2.5071e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6274e-02, -1.8274e-03,  2.2195e-02],\n",
       "                        [-3.9242e-02, -2.6047e-02,  3.2152e-02],\n",
       "                        [ 3.7798e-02,  2.6034e-03, -1.1605e-03]],\n",
       "              \n",
       "                       [[-3.6156e-02, -2.7064e-02, -8.6997e-03],\n",
       "                        [ 2.2546e-02, -3.3085e-02,  7.3288e-03],\n",
       "                        [ 1.7441e-02, -9.1410e-03, -1.4159e-02]],\n",
       "              \n",
       "                       [[-1.1977e-02, -1.6765e-02, -3.7746e-02],\n",
       "                        [ 3.2048e-02,  3.0754e-02,  8.0139e-03],\n",
       "                        [-2.0674e-02,  1.2050e-02,  1.3567e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0935e-02,  2.0450e-02,  2.4666e-02],\n",
       "                        [ 1.5512e-02, -3.2377e-02,  3.3219e-02],\n",
       "                        [ 3.8202e-02, -1.6083e-02,  9.6351e-03]],\n",
       "              \n",
       "                       [[ 6.5982e-03, -8.4959e-03,  5.1555e-04],\n",
       "                        [-2.2151e-02,  1.5857e-02, -2.7418e-02],\n",
       "                        [-1.1737e-03, -2.7482e-02, -2.9330e-02]],\n",
       "              \n",
       "                       [[-3.7841e-02,  1.2915e-02, -1.0636e-02],\n",
       "                        [ 2.7195e-02, -1.9293e-02, -2.9139e-03],\n",
       "                        [ 2.1054e-02,  6.8875e-03,  3.3250e-02]]]])),\n",
       "             ('model.features.conv_block4.cl.bias',\n",
       "              tensor([-0.0133, -0.0162, -0.0303,  0.0311,  0.0395, -0.0005, -0.0148, -0.0216,\n",
       "                       0.0089,  0.0162,  0.0355,  0.0288,  0.0384,  0.0373, -0.0172,  0.0153,\n",
       "                       0.0338, -0.0080, -0.0165,  0.0381, -0.0224,  0.0219,  0.0015, -0.0325,\n",
       "                      -0.0104,  0.0236,  0.0137,  0.0290, -0.0258,  0.0148,  0.0373,  0.0401,\n",
       "                       0.0057,  0.0044,  0.0220, -0.0290, -0.0142,  0.0128,  0.0008,  0.0144,\n",
       "                       0.0078,  0.0155,  0.0027,  0.0384, -0.0010, -0.0340,  0.0212,  0.0170,\n",
       "                       0.0251,  0.0324,  0.0351,  0.0172,  0.0341,  0.0165,  0.0121, -0.0213,\n",
       "                      -0.0208,  0.0145,  0.0223, -0.0110,  0.0218,  0.0278, -0.0055, -0.0168])),\n",
       "             ('model.features.conv_block4.bn.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('model.features.conv_block4.bn.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('model.features.conv_block4.bn.running_mean',\n",
       "              tensor([ 0.0012,  0.0922, -0.1172,  0.1533,  0.0105, -0.2257,  0.0892, -0.0395,\n",
       "                      -0.0883,  0.0107,  0.0111, -0.1956, -0.0716, -0.1515,  0.1039,  0.1725,\n",
       "                      -0.0439,  0.0030, -0.0038, -0.2941,  0.0917, -0.0447, -0.1137,  0.3024,\n",
       "                       0.2471,  0.1878, -0.2666,  0.0270,  0.1093,  0.0356,  0.1378, -0.0593,\n",
       "                      -0.1585,  0.1344,  0.1605, -0.0209, -0.0856,  0.1266, -0.0329, -0.0016,\n",
       "                       0.1552, -0.0798, -0.0353, -0.0454, -0.0566, -0.0870, -0.3680,  0.0732,\n",
       "                      -0.1738, -0.0109,  0.0115,  0.2553, -0.0344,  0.1322,  0.0180, -0.0657,\n",
       "                      -0.0531,  0.0032, -0.0525, -0.0233, -0.0430,  0.0452, -0.0290, -0.1549])),\n",
       "             ('model.features.conv_block4.bn.running_var',\n",
       "              tensor([0.8379, 0.8384, 0.8393, 0.8398, 0.8397, 0.8372, 0.8379, 0.8374, 0.8390,\n",
       "                      0.8354, 0.8347, 0.8385, 0.8379, 0.8394, 0.8411, 0.8375, 0.8362, 0.8397,\n",
       "                      0.8381, 0.8357, 0.8401, 0.8388, 0.8403, 0.8407, 0.8412, 0.8388, 0.8411,\n",
       "                      0.8390, 0.8409, 0.8383, 0.8423, 0.8357, 0.8366, 0.8388, 0.8367, 0.8396,\n",
       "                      0.8370, 0.8393, 0.8392, 0.8379, 0.8367, 0.8374, 0.8403, 0.8386, 0.8365,\n",
       "                      0.8353, 0.8357, 0.8391, 0.8368, 0.8401, 0.8374, 0.8378, 0.8399, 0.8398,\n",
       "                      0.8377, 0.8370, 0.8406, 0.8376, 0.8375, 0.8363, 0.8382, 0.8378, 0.8373,\n",
       "                      0.8365])),\n",
       "             ('model.features.conv_block4.bn.num_batches_tracked', tensor(2)),\n",
       "             ('model.out.weight',\n",
       "              tensor([[ 1.3976e-02, -2.2298e-02,  4.1014e-02,  ...,  2.9085e-02,\n",
       "                       -2.5434e-02,  3.1472e-02],\n",
       "                      [ 1.4059e-02, -8.5345e-04,  8.0341e-03,  ...,  3.6558e-02,\n",
       "                        3.3003e-02,  2.5197e-02],\n",
       "                      [-3.2516e-02, -2.7478e-05,  3.0782e-03,  ..., -7.3217e-03,\n",
       "                        3.2358e-02,  4.0398e-02],\n",
       "                      [ 2.5058e-02,  3.4104e-02,  6.7627e-03,  ..., -3.3432e-02,\n",
       "                        2.8104e-02, -2.5581e-02],\n",
       "                      [ 1.9341e-02,  1.6546e-02,  2.1527e-02,  ...,  3.0894e-02,\n",
       "                        7.3708e-03, -3.0072e-02]])),\n",
       "             ('model.out.bias', tensor([0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([5, 576])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv4(\n",
      "  (criterion): CrossEntropyLoss()\n",
      "  (model): ModuleDict(\n",
      "    (features): Sequential(\n",
      "      (conv_block1): ConvBlock(\n",
      "        (cl): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_block2): ConvBlock(\n",
      "        (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_block3): ConvBlock(\n",
      "        (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv_block4): ConvBlock(\n",
      "        (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (flatten): Flatten()\n",
      "    )\n",
      "    (out): Linear(in_features=576, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "ModuleDict(\n",
      "  (features): Sequential(\n",
      "    (conv_block1): ConvBlock(\n",
      "      (cl): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv_block2): ConvBlock(\n",
      "      (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv_block3): ConvBlock(\n",
      "      (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv_block4): ConvBlock(\n",
      "      (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (flatten): Flatten()\n",
      "  )\n",
      "  (out): Linear(in_features=576, out_features=5, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_block1): ConvBlock(\n",
      "    (cl): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block2): ConvBlock(\n",
      "    (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block3): ConvBlock(\n",
      "    (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block4): ConvBlock(\n",
      "    (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten()\n",
      ")\n",
      "ConvBlock(\n",
      "  (cl): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "ConvBlock(\n",
      "  (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "ConvBlock(\n",
      "  (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "ConvBlock(\n",
      "  (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Flatten()\n",
      "Linear(in_features=576, out_features=5, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for m in net.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([5, 576])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "params = [p.clone() for p in net.parameters()]\n",
    "for p in params:\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3362, -0.3457,  0.2306,  0.8330,  0.2908],\n",
       "        [ 0.6396,  0.3738,  0.3854,  1.3634, -0.6434],\n",
       "        [-0.2011, -0.2519,  0.0889,  0.4364,  0.4442],\n",
       "        [-0.0638,  0.0974,  0.1478,  0.7692,  1.1554],\n",
       "        [-0.5798, -0.4272,  0.7046,  0.8038, -0.4332],\n",
       "        [ 0.2616, -0.5926,  0.1327,  1.1268,  0.6443],\n",
       "        [-0.5332, -0.2635,  0.2796,  0.4469, -0.2072],\n",
       "        [ 0.5241, -0.2585, -0.6114,  0.7591,  0.2480],\n",
       "        [-0.2637, -0.7140, -0.0376,  0.6397,  0.2597],\n",
       "        [ 0.6517, -0.0873, -0.0939,  0.1118,  0.2408],\n",
       "        [ 0.2259,  0.0901, -0.1242, -0.3037,  0.1042],\n",
       "        [-0.0172, -0.7188, -0.3114,  0.8026,  0.0560],\n",
       "        [-0.1121,  0.1682,  0.6484,  0.4677, -0.1027],\n",
       "        [-0.1661, -0.5331, -0.0911,  0.4549,  0.1270],\n",
       "        [ 0.5297, -0.0837,  0.5027,  0.7789, -0.1117],\n",
       "        [-0.0472, -0.0667, -0.4084,  0.6294,  0.2110],\n",
       "        [ 0.0338, -0.1865, -0.4882,  1.0022,  0.8640],\n",
       "        [-0.7050, -0.8805, -0.2131,  0.3589,  0.4273],\n",
       "        [ 0.4612, -0.9792,  0.2190,  0.0470, -0.3204],\n",
       "        [ 0.7658, -0.0597, -0.0242,  0.7184,  0.5704]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward_weights(rnd1, params)\n",
    "net.forward_weights(rnd2, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv4(\n",
       "  (b1): ConvBlock(\n",
       "    (cl): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (b2): ConvBlock(\n",
       "    (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (b3): ConvBlock(\n",
       "    (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (b4): ConvBlock(\n",
       "    (cl): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten()\n",
       "  (ln): Linear(in_features=576, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.b1.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3925e-02,  7.0432e-04, -1.3839e-02, -1.6129e-02, -1.2448e-02,\n",
       "         5.7674e-03,  1.2532e-02, -1.7968e-02,  6.8724e-05,  9.4719e-03,\n",
       "         5.2149e-03,  2.7249e-03, -1.8871e-02, -1.1634e-02,  1.3996e-02,\n",
       "        -1.4961e-02, -9.1287e-03,  4.0561e-03,  3.8911e-03, -1.8237e-02,\n",
       "         4.5349e-03, -1.6668e-04, -1.7990e-02, -6.9514e-03, -1.2812e-02,\n",
       "         5.3805e-03, -6.0133e-03,  5.2909e-03, -9.4729e-03,  1.5352e-02,\n",
       "         1.4413e-02,  1.4477e-02,  4.5343e-03, -1.7874e-02, -1.6274e-02,\n",
       "         5.9854e-03, -9.3215e-03, -1.1341e-02,  5.2735e-03,  1.2337e-02,\n",
       "         1.7256e-02, -1.2733e-02, -5.1462e-03,  7.5638e-03, -5.6074e-03,\n",
       "        -1.7929e-02,  9.8292e-04,  4.2408e-04,  1.9868e-03, -9.7916e-03,\n",
       "         5.6999e-03,  1.4295e-02, -1.0192e-02, -1.7191e-02, -1.5342e-02,\n",
       "         5.6219e-04,  1.8214e-02, -1.7145e-02,  1.2474e-02, -1.6087e-02,\n",
       "         1.7220e-02, -6.0655e-03, -1.2193e-02, -3.5053e-03])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bn.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3925e-02,  7.0432e-04, -1.3839e-02, -1.6129e-02, -1.2448e-02,\n",
       "         5.7674e-03,  1.2532e-02, -1.7968e-02,  6.8724e-05,  9.4719e-03,\n",
       "         5.2149e-03,  2.7249e-03, -1.8871e-02, -1.1634e-02,  1.3996e-02,\n",
       "        -1.4961e-02, -9.1287e-03,  4.0561e-03,  3.8911e-03, -1.8237e-02,\n",
       "         4.5349e-03, -1.6668e-04, -1.7990e-02, -6.9514e-03, -1.2812e-02,\n",
       "         5.3805e-03, -6.0133e-03,  5.2909e-03, -9.4729e-03,  1.5352e-02,\n",
       "         1.4413e-02,  1.4477e-02,  4.5343e-03, -1.7874e-02, -1.6274e-02,\n",
       "         5.9854e-03, -9.3215e-03, -1.1341e-02,  5.2735e-03,  1.2337e-02,\n",
       "         1.7256e-02, -1.2733e-02, -5.1462e-03,  7.5638e-03, -5.6074e-03,\n",
       "        -1.7929e-02,  9.8292e-04,  4.2408e-04,  1.9868e-03, -9.7916e-03,\n",
       "         5.6999e-03,  1.4295e-02, -1.0192e-02, -1.7191e-02, -1.5342e-02,\n",
       "         5.6219e-04,  1.8214e-02, -1.7145e-02,  1.2474e-02, -1.6087e-02,\n",
       "         1.7220e-02, -6.0655e-03, -1.2193e-02, -3.5053e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1623, -0.0017,  0.0474],\n",
      "          [-0.0299, -0.1153, -0.1814],\n",
      "          [ 0.0328,  0.0757, -0.1247]],\n",
      "\n",
      "         [[-0.0926,  0.0803,  0.0312],\n",
      "          [-0.1704,  0.1027,  0.1454],\n",
      "          [-0.0988,  0.0387,  0.0800]],\n",
      "\n",
      "         [[ 0.0039, -0.0360,  0.1487],\n",
      "          [-0.0547,  0.1525,  0.1786],\n",
      "          [-0.1867,  0.0908,  0.1110]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1720, -0.0133,  0.1300],\n",
      "          [-0.1436, -0.1104, -0.0792],\n",
      "          [-0.0509, -0.0066,  0.0674]],\n",
      "\n",
      "         [[ 0.0087,  0.0206,  0.0270],\n",
      "          [-0.0970,  0.0400,  0.0800],\n",
      "          [-0.1621,  0.1012,  0.1042]],\n",
      "\n",
      "         [[-0.1638,  0.0293,  0.0713],\n",
      "          [ 0.1578,  0.1033,  0.0822],\n",
      "          [-0.1699,  0.1017,  0.1795]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1901,  0.1152, -0.1482],\n",
      "          [ 0.0663, -0.1590,  0.0401],\n",
      "          [-0.0292, -0.1539, -0.1601]],\n",
      "\n",
      "         [[ 0.0139,  0.1563, -0.0862],\n",
      "          [-0.1825, -0.1088,  0.0695],\n",
      "          [-0.0366, -0.1760, -0.0197]],\n",
      "\n",
      "         [[-0.0721,  0.1476, -0.0823],\n",
      "          [-0.0906,  0.0757, -0.1253],\n",
      "          [-0.0314, -0.0129,  0.1761]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0092, -0.0724,  0.0079],\n",
      "          [-0.1846,  0.0609, -0.0990],\n",
      "          [-0.1812, -0.0003,  0.1095]],\n",
      "\n",
      "         [[ 0.0556,  0.1034,  0.0860],\n",
      "          [-0.0683,  0.1477,  0.0785],\n",
      "          [ 0.0538, -0.0146,  0.0169]],\n",
      "\n",
      "         [[ 0.1140,  0.1537,  0.1509],\n",
      "          [ 0.0543, -0.1496,  0.0589],\n",
      "          [ 0.1173,  0.0619, -0.1451]]],\n",
      "\n",
      "\n",
      "        [[[-0.1052, -0.0620, -0.0413],\n",
      "          [-0.0037,  0.1811, -0.0876],\n",
      "          [-0.0294, -0.1718, -0.0296]],\n",
      "\n",
      "         [[ 0.0218,  0.1147,  0.0902],\n",
      "          [-0.0124, -0.1755, -0.1344],\n",
      "          [-0.0112, -0.1311,  0.0306]],\n",
      "\n",
      "         [[-0.1071,  0.0281, -0.0552],\n",
      "          [ 0.1287, -0.1738,  0.1219],\n",
      "          [-0.0433, -0.1061,  0.0264]]],\n",
      "\n",
      "\n",
      "        [[[-0.1003,  0.1618,  0.0124],\n",
      "          [-0.0923, -0.0875, -0.1918],\n",
      "          [ 0.1647,  0.1815, -0.0043]],\n",
      "\n",
      "         [[ 0.0018,  0.1885, -0.0765],\n",
      "          [-0.0617,  0.0443, -0.1316],\n",
      "          [-0.1389,  0.0111,  0.1312]],\n",
      "\n",
      "         [[ 0.0216,  0.0490, -0.1049],\n",
      "          [-0.1563,  0.1193,  0.1874],\n",
      "          [-0.0201, -0.0811, -0.1108]]]], grad_fn=<CloneBackward>)\n",
      "tensor([-0.1394,  0.0061, -0.1372, -0.1611, -0.1246,  0.0576,  0.1232, -0.1770,\n",
      "         0.0010,  0.0921,  0.0504,  0.0260, -0.1894, -0.1154,  0.1402, -0.1499,\n",
      "        -0.0906,  0.0410,  0.0408, -0.1846,  0.0479, -0.0007, -0.1798, -0.0698,\n",
      "        -0.1299,  0.0537, -0.0612,  0.0558, -0.0935,  0.1530,  0.1436,  0.1439,\n",
      "         0.0437, -0.1780, -0.1611,  0.0609, -0.0946, -0.1132,  0.0526,  0.1230,\n",
      "         0.1698, -0.1279, -0.0513,  0.0751, -0.0552, -0.1782,  0.0083,  0.0035,\n",
      "         0.0197, -0.0966,  0.0559,  0.1427, -0.1002, -0.1715, -0.1534,  0.0060,\n",
      "         0.1832, -0.1724,  0.1263, -0.1617,  0.1727, -0.0617, -0.1205, -0.0349],\n",
      "       grad_fn=<CloneBackward>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<CloneBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<CloneBackward>)\n"
     ]
    }
   ],
   "source": [
    "for p in params:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3925e-02,  7.0432e-04, -1.3839e-02, -1.6129e-02, -1.2448e-02,\n",
       "         5.7674e-03,  1.2532e-02, -1.7968e-02,  6.8724e-05,  9.4719e-03,\n",
       "         5.2149e-03,  2.7249e-03, -1.8871e-02, -1.1634e-02,  1.3996e-02,\n",
       "        -1.4961e-02, -9.1287e-03,  4.0561e-03,  3.8911e-03, -1.8237e-02,\n",
       "         4.5349e-03, -1.6668e-04, -1.7990e-02, -6.9514e-03, -1.2812e-02,\n",
       "         5.3805e-03, -6.0133e-03,  5.2909e-03, -9.4729e-03,  1.5352e-02,\n",
       "         1.4413e-02,  1.4477e-02,  4.5343e-03, -1.7874e-02, -1.6274e-02,\n",
       "         5.9854e-03, -9.3215e-03, -1.1341e-02,  5.2735e-03,  1.2337e-02,\n",
       "         1.7256e-02, -1.2733e-02, -5.1462e-03,  7.5638e-03, -5.6074e-03,\n",
       "        -1.7929e-02,  9.8292e-04,  4.2408e-04,  1.9868e-03, -9.7916e-03,\n",
       "         5.6999e-03,  1.4295e-02, -1.0192e-02, -1.7191e-02, -1.5342e-02,\n",
       "         5.6219e-04,  1.8214e-02, -1.7145e-02,  1.2474e-02, -1.6087e-02,\n",
       "         1.7220e-02, -6.0655e-03, -1.2193e-02, -3.5053e-03])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bn.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaxPool2d' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8799dc317a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/Metalearning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaxPool2d' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "net.mp.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([5, 576])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "amplitude = np.random.uniform(0.1, 5.0)\n",
    "phase = np.random.uniform(0, np.pi)\n",
    "\n",
    "def fn(x):\n",
    "    return amplitude * np.sin(x + phase)\n",
    "\n",
    "np.random.seed(1337)\n",
    "x = np.random.uniform(-5.0, 5.0, 1000)\n",
    "y = fn(x).reshape(-1, 1)\n",
    "\n",
    "sorted_indices = np.argsort(x)\n",
    "\n",
    "train_x = np.random.uniform(-5.0, 5.0, 5)\n",
    "train_y = fn(train_x)\n",
    "test_x = np.random.uniform(-5.0, 5.0, 50)\n",
    "test_y = fn(test_x)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"Example sine wave\", fontsize=16)\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"y\", fontsize=16)\n",
    "\n",
    "plt.plot(x[sorted_indices],y[sorted_indices])\n",
    "plt.scatter(test_x, test_y, color=\"red\", label=\"Query set\")\n",
    "plt.scatter(train_x, train_y, color=\"blue\", label=\"Support set\")\n",
    "plt.legend(fontsize=16)\n",
    "plt.savefig(\"sinewave.png\")\n",
    "plt.show()\n",
    "\n",
    "#plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_after: 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_after: 2500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_after: 5000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_after: 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for val_after in [1000, 2500, 5000, 10000]:\n",
    "    print(\"val_after:\", val_after)\n",
    "    t = 70000 // val_after\n",
    "    x = [i*t for i in range(val_after)]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(x, [-1 if _%2==0 else +1 for _ in range(len(x))])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0]\n",
    "for k in range(70000):\n",
    "    pass\n",
    "    if (k+1) % 5000 == 0:\n",
    "        t.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t) == 1 + 70000//5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test = {\"technique\":dict()}\n",
    "df = pd.read_csv(\"test.csv\", index_col=0)\n",
    "for col in [\"mean_loss\", \"median_loss\"]:\n",
    "    mean, count, std = df[col].agg([\"mean\", \"count\", \"std\"])\n",
    "    # Error bound for 95% confidence-interval\n",
    "    eb = 1.96*std/np.sqrt(count)\n",
    "    display_string = f\"{mean:.2f} \\\\pm {eb:.2f}\"\n",
    "    test[\"technique\"][f\"5-shot-{col.split('_')[0]}\"] = display_string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-shot-mean</th>\n",
       "      <th>5-shot-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>technique</th>\n",
       "      <td>0.42 \\pm 0.24</td>\n",
       "      <td>0.61 \\pm 0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             5-shot-mean  5-shot-median\n",
       "technique  0.42 \\pm 0.24  0.61 \\pm 0.27"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(test, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'> <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(eb), type(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from os.path import join\n",
    "\n",
    "def iterator(cdir):\n",
    "    cdir = \"./results2/sine/\"\n",
    "    subproblems = os.listdir(cdir)\n",
    "    paths = {x:join(cdir, x) for x in subproblems}\n",
    "    \n",
    "    for problem in paths.keys():\n",
    "        # Path to ptoblem folder e.g. k5test50\n",
    "        path = paths[problem]\n",
    "        for alg in os.listdir(path):\n",
    "            alg_path = join(path, alg)\n",
    "            filepath = join(alg_path, \"curves200.csv\")\n",
    "            yield alg, problem, filepath\n",
    "\n",
    "results = dict()    \n",
    "for alg, problem, path in iterator(\"\"):\n",
    "    if not alg in results:\n",
    "        results[alg] = dict()    \n",
    "        \n",
    "    b = np.random.randint(-100,100)\n",
    "    a = np.random.uniform(-3,3)\n",
    "    curve = [b]\n",
    "\n",
    "    x = 0\n",
    "    for _ in range(100):\n",
    "        x += 200\n",
    "        curve.append(a*x + b)\n",
    "    curve=np.array(curve)\n",
    "\n",
    "    with open(path, \"w+\", newline=\"\") as f:\n",
    "        for _ in range(30):\n",
    "            noise = np.random.uniform(-10000,10000, size=len(curve))\n",
    "            ccurve = curve + noise\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(list(ccurve))\n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "\n",
    "mse(torch.from_numpy(np.array([0])), torch.from_numpy(np.array([np.nan])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array([np.nan])).item() == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "a = torch.from_numpy(np.array([np.nan])).item()\n",
    "math.isnan(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t = [torch.rand((100,50)).to(\"cuda:1\") for _ in [None]*5]\n",
    "for p in t:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[100.9773, 100.2396, 100.3401,  ..., 100.4817, 100.5670, 100.2770],\n",
      "        [100.7956, 100.1046, 100.2581,  ..., 100.7958, 100.0183, 100.9593],\n",
      "        [100.4359, 100.7473, 100.9513,  ..., 100.4242, 100.2806, 100.4053],\n",
      "        ...,\n",
      "        [100.9179, 100.6894, 100.9140,  ..., 100.5213, 100.4700, 100.7855],\n",
      "        [100.1107, 100.5180, 100.5580,  ..., 100.9978, 100.0025, 100.5262],\n",
      "        [100.0072, 100.2208, 100.1699,  ..., 100.6022, 100.6710, 100.1011]],\n",
      "       device='cuda:1', grad_fn=<AddBackward0>), tensor([[100.1238, 100.5368, 100.9997,  ..., 100.1742, 100.8744, 100.6582],\n",
      "        [100.0757, 100.4531, 100.8615,  ..., 100.7631, 100.2943, 100.7802],\n",
      "        [100.5361, 100.6792, 100.7111,  ..., 100.0274, 100.1506, 100.0832],\n",
      "        ...,\n",
      "        [100.2898, 100.0547, 100.5717,  ..., 100.4359, 100.5694, 100.3634],\n",
      "        [100.0735, 100.5821, 100.2731,  ..., 100.7474, 100.3260, 100.9854],\n",
      "        [100.9591, 100.1673, 100.2675,  ..., 100.8791, 100.4353, 100.4077]],\n",
      "       device='cuda:1', grad_fn=<AddBackward0>), tensor([[100.2875, 100.5216, 100.7998,  ..., 100.7803, 100.3991, 100.2757],\n",
      "        [100.4760, 100.0880, 100.0599,  ..., 100.2564, 100.8135, 100.6418],\n",
      "        [100.4833, 100.6294, 100.2699,  ..., 100.7482, 100.2414, 100.2217],\n",
      "        ...,\n",
      "        [100.8365, 100.3642, 100.1905,  ..., 100.5651, 100.1413, 100.6566],\n",
      "        [100.4719, 100.8016, 100.4558,  ..., 100.0265, 100.3205, 100.0005],\n",
      "        [100.7027, 100.9570, 100.7838,  ..., 100.9612, 100.9474, 100.6553]],\n",
      "       device='cuda:1', grad_fn=<AddBackward0>), tensor([[100.8936, 100.5595, 100.9203,  ..., 100.8498, 100.3159, 100.2739],\n",
      "        [100.9247, 100.4849, 100.7838,  ..., 100.5887, 100.7945, 100.2514],\n",
      "        [100.7333, 100.7883, 100.1585,  ..., 100.1841, 100.4939, 100.8215],\n",
      "        ...,\n",
      "        [100.0498, 100.6289, 100.6826,  ..., 100.7908, 100.3823, 100.9101],\n",
      "        [100.7606, 100.1486, 100.3990,  ..., 100.2220, 100.4544, 100.8719],\n",
      "        [100.5504, 100.9964, 100.7396,  ..., 100.4710, 100.8818, 100.0784]],\n",
      "       device='cuda:1', grad_fn=<AddBackward0>), tensor([[100.7490, 100.7047, 100.9010,  ..., 100.7763, 100.5761, 100.6471],\n",
      "        [100.3574, 100.3936, 100.5716,  ..., 100.9889, 100.8969, 100.4243],\n",
      "        [100.3080, 100.8454, 100.2223,  ..., 100.5233, 100.5852, 100.9977],\n",
      "        ...,\n",
      "        [100.6347, 100.7817, 100.8637,  ..., 100.6774, 100.9127, 100.8619],\n",
      "        [100.0387, 100.2638, 100.4638,  ..., 100.3326, 100.3945, 100.0659],\n",
      "        [100.2559, 100.1724, 100.6622,  ..., 100.9409, 100.6568, 100.5944]],\n",
      "       device='cuda:1', grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "def dump_state():\n",
    "    return t\n",
    "\n",
    "b = dump_state()\n",
    "for i in range(len(t)):\n",
    "    t[i] = 100 + t[i]\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [p.clone().detach() for p in t]\n",
    "c[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[100.9412, 100.6778, 100.6372,  ..., 100.5865, 100.7122, 100.6730],\n",
       "         [100.4496, 100.6378, 100.9269,  ..., 100.0872, 100.6008, 100.8045],\n",
       "         [100.0959, 100.0948, 100.4687,  ..., 100.5612, 100.8825, 100.7796],\n",
       "         ...,\n",
       "         [100.0581, 100.2077, 100.9890,  ..., 100.3224, 100.1400, 100.6821],\n",
       "         [100.5894, 100.8306, 100.7107,  ..., 100.6254, 100.4091, 100.3201],\n",
       "         [100.0464, 100.8001, 100.5733,  ..., 100.2850, 100.3102, 100.1197]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[100.9855, 100.1118, 100.6672,  ..., 100.4890, 100.4161, 100.0905],\n",
       "         [100.3765, 100.7330, 100.9948,  ..., 100.7332, 100.1602, 100.6035],\n",
       "         [100.9186, 100.9936, 100.6308,  ..., 100.5786, 100.1804, 100.1735],\n",
       "         ...,\n",
       "         [100.9416, 100.8245, 100.3751,  ..., 100.3025, 100.8629, 100.6757],\n",
       "         [100.7120, 100.6272, 100.4756,  ..., 100.8254, 100.0339, 100.2723],\n",
       "         [100.2267, 100.4618, 100.7785,  ..., 100.3423, 100.7805, 100.1571]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[100.5222, 100.5856, 100.7047,  ..., 100.3199, 100.4862, 100.2132],\n",
       "         [100.3256, 100.8427, 100.3119,  ..., 100.9068, 100.5413, 100.0832],\n",
       "         [100.9184, 100.1893, 100.5002,  ..., 100.9953, 100.7956, 100.6296],\n",
       "         ...,\n",
       "         [100.3901, 100.2092, 100.6107,  ..., 100.7055, 100.4218, 100.3379],\n",
       "         [100.5831, 100.8908, 100.4603,  ..., 100.1624, 100.4048, 100.4534],\n",
       "         [100.1058, 100.1652, 100.7926,  ..., 100.3320, 100.2018, 100.8560]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[100.8747, 100.2891, 100.2543,  ..., 100.7882, 100.0011, 100.1690],\n",
       "         [100.8880, 100.8733, 100.2977,  ..., 100.8203, 100.0131, 100.2064],\n",
       "         [100.0589, 100.2756, 100.8648,  ..., 100.9934, 100.9246, 100.0616],\n",
       "         ...,\n",
       "         [100.9282, 100.6701, 100.4019,  ..., 100.0219, 100.9616, 100.8487],\n",
       "         [100.3308, 100.3884, 100.6910,  ..., 100.7615, 100.8715, 100.8696],\n",
       "         [100.8140, 100.5358, 100.3011,  ..., 100.1501, 100.8034, 100.5196]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[100.4518, 100.6825, 100.0275,  ..., 100.9212, 100.6839, 100.5332],\n",
       "         [100.2374, 100.6906, 100.4526,  ..., 100.9668, 100.7747, 100.0075],\n",
       "         [100.8546, 100.5193, 100.1069,  ..., 100.3265, 100.4033, 100.7053],\n",
       "         ...,\n",
       "         [100.3361, 100.3575, 100.7715,  ..., 100.5757, 100.4663, 100.3237],\n",
       "         [100.1112, 100.5063, 100.5475,  ..., 100.6911, 100.9478, 100.6635],\n",
       "         [100.4116, 100.2286, 100.9524,  ..., 100.0141, 100.9049, 100.3176]],\n",
       "        grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "tuples = []\n",
    "\n",
    "\n",
    "\n",
    "test = OrderedDict([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bca3b96492b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
